#!/usr/bin/env ruby -wU --disable-all

require "digest/sha2"
require "fileutils"
require "find"
require "io/console"
require "json"
require "net/http"
require "open3"
require "optparse"
require "pathname"
require "psych"
require "rbconfig"
require "rubygems" # TODO write a simple version of Gem::Package::TarReader?
require "rubygems/package"
require "set"
require "shellwords"
require "stringio"
require "tempfile"
require "tmpdir"
require "uri"
require "zlib"

module Wake
  def self.run(*args)
    options = { debug: false, jobs: 1 }
    parser = OptionParser.new
    parser.on("-d", "--debug")
    parser.on("-j", "--jobs=NUM", Integer)
    parser.order(args, into: options)

    console = Console.new(STDOUT)
    $stdout = console

    registry = Registry.new

    define_rules(registry, console: console, debugging_enabled: options.fetch(:debug))

    Pathname.glob("**/BUILD") do |build|
      registry.new_package(build.dirname.to_path).instance_eval(build.read, build.to_path)
    end

    targets = registry.resolve(platform: Platform.new(host_os: RbConfig::CONFIG.fetch("host_os")))
    actions = Actions.new(console, RealFilesystem.new(Dir.pwd))
    providers = ProviderRegistry.new

    plan = Plan.new(targets.keys) { |label| targets.fetch(label).dependencies }

    workers = Array.new(options.fetch(:jobs)) do
      Thread.new do
        plan.each do |label|
          context = Context.new(actions, providers, label)
          target = targets.fetch(label)
          console.report_target_invocation(label)
          target.invoke(context)
          console.report_target_completion(label)
        end
      end
    end

    workers.each(&:join)

    broken_tests = []
    tests = providers.of(TestExecutableInfo)
    test_plan = Plan.new(tests.keys) { |label| [] } # no dependencies
    test_plan.each do |label|
      test = tests.fetch(label)
      out = File.join(label.package, "#{label.name}-out.txt")
      process_test_output = lambda do |io|
        until io.eof?
          test_case = TestCase.json_create(JSON.parse(io.readline.chomp))
          console.report_test_result(test_case)
          broken_tests << test_case if test_case.broken?
        end
      end

      action_did_run = false

      actions.run(label, inputs: [test.executable, *test.runfiles], parameters: [*test.arguments, *test.env.flatten], outputs: [out]) do |fs|
        action_did_run = true
        rd, wr = IO.pipe
        reader = Thread.new(rd, &process_test_output)
        fs.open(out, "wb") do |io|
          fs.exec!(test.executable, *test.arguments, out: CompositeIO.new(io, wr), env: test.env)
        end
        wr.close
        reader.join
      end

      if !action_did_run
        # TODO var/tmp is duplication with Actions
        File.open(File.join("var/tmp", out), "rb", &process_test_output)
      end
    end

    console.join

    actions.expire(before: Time.now - (60 * 60 * 24))

    broken_tests.count
  end

  def self.define_rules(registry, console:, debugging_enabled:)
    registry.new_target(
      label: Label.parse("//tools:console"),
      # Dummy for now because ruby 2.5.3 on Travis otherwise complains splatting no kwargs.
      rule: lambda { |context, dummy:| [console] },
      attributes: AttributeSchema.new({ dummy: Attribute.new(String) }).parse({ dummy: "42" }),
    )

    registry.new_target(
      label: Label.parse("//tools:http"),
      rule: lambda { |context, console:| [HttpDownloader.new(console.fetch(Console))] },
      attributes: AttributeSchema.new({
        console: Attribute.new(Label, default: "//tools:console", providers: [Console]),
      }).parse({}),
    )

    registry.new_rule(
      :http_file,
      attributes: {
        http: Attribute.new(Label, default: "//tools:http", providers: [HttpDownloader]),
        url: Attribute.new(URI),
        sha256: Attribute.new(Verifier),
      },
      implementation: ->(context, http:, url:, sha256:) {
        path = context.expand_path(url.path.split("/").last)
        # TODO work back in (a new kind of?) verifier
        context.run(parameters: [url], outputs: [path]) do |fs|
          fs.open(path, "wb") do |io|
            http.fetch(HttpDownloader).get(url, io)
          end
        end
        [FileInfo.new(path)]
      },
    )

    registry.new_rule(
      :extract,
      attributes: {
        archive: Attribute.new(Label, providers: [FileInfo]),
        format: Attribute.new(Extractor),
        paths: Attribute.new(String, list: true),
        permissions: Attribute.new(Integer, default: 0644),
        strip_components: Attribute.new(PathCleaner, default: 0),
      },
      implementation: ->(context, archive:, format:, paths:, permissions:, strip_components:) {
        context.run(inputs: [archive.fetch(FileInfo).path], parameters: [format, paths, permissions, strip_components], outputs: paths.map { |path| context.expand_path(path) }) do |fs|
          fs.open(archive.fetch(FileInfo).path, "rb") do |archive_io|
            format.extract(archive_io, strip_components: strip_components) do |entry_path, entry_io|
              if paths.include?(entry_path)
                fs.open(context.expand_path(entry_path), "wb", permissions: permissions) do |output_io|
                  IO.copy_stream(entry_io, output_io)
                end
              end
            end
          end
        end

        file_group_info = FileGroupInfo.new(paths.map { |path| context.expand_path(path) })
        result = [file_group_info]
        result << FileInfo.new(file_group_info.only) if paths.length == 1
        result
      },
    )

    registry.new_rule(
      :java_archiver,
      attributes: {
        jar: Attribute.new(Label, providers: [FileInfo]),
        libs: Attribute.new(Label, providers: [FileGroupInfo]),
      },
      implementation: ->(context, jar:, libs:) {
        [JavaArchiverInfo.new(
          jar: jar.fetch(FileInfo).path,
          libs: libs.fetch(FileGroupInfo).paths,
        )]
      },
    )
    registry.new_rule(
      :java_compiler,
      attributes: {
        javac: Attribute.new(Label, providers: [FileInfo]),
        libs: Attribute.new(Label, providers: [FileGroupInfo]),
      },
      implementation: ->(context, javac:, libs:) {
        [JavaCompilerInfo.new(
          javac: javac.fetch(FileInfo).path,
          libs: libs.fetch(FileGroupInfo).paths,
        )]
      },
    )

    registry.new_rule(
      :java_import,
      attributes: {
        jar: Attribute.new(Label, providers: [FileInfo]),
        neverlink: Attribute.new(TrueClass, default: false),
      },
      implementation: ->(context, jar:, neverlink:) {
        [JavaInfo.new(
          jar: jar.fetch(FileInfo).path,
          deps: [],
          neverlink: neverlink,
        )]
      },
    )

    registry.new_rule(
      :java_lib,
      attributes: {
        compiler: Attribute.new(Label, default: "//lib/java:compiler", providers: [JavaCompilerInfo]),
        srcs: Attribute.new(String, list: true),
        deps: Attribute.new(Label, list: true, providers: [JavaInfo]),
      },
      implementation: ->(context, deps:, compiler:, srcs:) {
        jdk = compiler.fetch(JavaCompilerInfo)
        jdk.compile(srcs: srcs, deps: deps, context: context)
      },
    )

    registry.new_rule(
      :java_runtime,
      attributes: {
        java: Attribute.new(Label, providers: [FileInfo]),
        libs: Attribute.new(Label, providers: [FileGroupInfo]),
      },
      implementation: ->(context, java:, libs:) {
        [JavaRuntimeInfo.new(
          java: java.fetch(FileInfo).path,
          libs: libs.fetch(FileGroupInfo).paths,
        )]
      },
    )

    registry.new_rule(
      :kotlin_compiler,
      attributes: {
        java_archiver: Attribute.new(Label, default: "//lib/java:archiver", providers: [JavaArchiverInfo]),
        java_runtime: Attribute.new(Label, default: "//lib/java:runtime", providers: [JavaRuntimeInfo]),
        preloader: Attribute.new(Label, providers: [FileInfo]),
        compiler: Attribute.new(Label, providers: [FileInfo]),
        stdlib: Attribute.new(Label, providers: [JavaInfo]),
        stdlib_js: Attribute.new(Label, providers: [KotlinJsInfo]),
        runtime: Attribute.new(Label, providers: [FileGroupInfo]),
      },
      implementation: ->(context, java_archiver:, java_runtime:, preloader:, compiler:, stdlib:, stdlib_js:, runtime:) {
        [
          KotlinJsCompilerInfo.new(
            java_archiver: java_archiver.fetch(JavaArchiverInfo),
            java_runtime: java_runtime.fetch(JavaRuntimeInfo),
            preloader: preloader.fetch(FileInfo).path,
            compiler: compiler.fetch(FileInfo).path,
            stdlib: stdlib.fetch(JavaInfo),
            stdlib_js: stdlib_js.fetch(KotlinJsInfo),
            runtime: runtime.fetch(FileGroupInfo).paths,
          ),
          KotlinJvmCompilerInfo.new(
            java_runtime: java_runtime.fetch(JavaRuntimeInfo),
            preloader: preloader.fetch(FileInfo).path,
            compiler: compiler.fetch(FileInfo).path,
            stdlib: stdlib.fetch(JavaInfo),
            runtime: runtime.fetch(FileGroupInfo).paths,
          ),
          KotlinNativeCompilerInfo.new(
            java_runtime: java_runtime.fetch(JavaRuntimeInfo),
          ),
        ]
      },
    )

    registry.new_rule(
      :kt_js_import,
      attributes: {
        jar: Attribute.new(Label, providers: [FileInfo]),
        js_path: Attribute.new(String),
      },
      implementation: ->(context, jar:, js_path:) {
        format = Extractor.parse(:zip)

        context.run(inputs: [jar.fetch(FileInfo).path], parameters: [format, js_path], outputs: [context.expand_path(js_path)]) do |fs|
          fs.open(jar.fetch(FileInfo).path, "rb") do |archive_io|
            # TODO can we nest strip_components inside the block instead? Would be nice to make it optional.
            # TODO and, while we're at it, couldn't we nest tar inside gzip in the same way? None of this @delegate stuff.
            format.extract(archive_io, strip_components: PathCleaner.parse(0)) do |entry_path, entry_io|
              if js_path == entry_path
                fs.open(context.expand_path(entry_path), "wb") do |output_io|
                  IO.copy_stream(entry_io, output_io)
                end
              end
            end
          end
        end

        [KotlinJsInfo.new(
          jar: jar.fetch(FileInfo).path,
          js: context.expand_path(js_path),
          deps: [],
        )]
      },
    )

    registry.new_rule(
      :kt_js_lib,
      attributes: {
        kotlin_compiler: Attribute.new(Label, default: "//lib/kotlin:compiler", providers: [KotlinJsCompilerInfo]),
        srcs: Attribute.new(String, list: true),
        deps: Attribute.new(Label, list: true, providers: [KotlinJsInfo]),
        plugins: Attribute.new(Label, list: true, default: [], providers: [JavaInfo]),
      },
      implementation: ->(context, kotlin_compiler:, srcs:, deps:, plugins:) {
        compiler = kotlin_compiler.fetch(KotlinJsCompilerInfo)
        compiler.compile(srcs: srcs, deps: deps, plugins: plugins, context: context)
      },
    )

    registry.new_rule(
      :kt_js_test,
      attributes: {
        kotlin_compiler: Attribute.new(Label, default: "//lib/kotlin:compiler", providers: [KotlinJsCompilerInfo]),
        srcs: Attribute.new(String, list: true),
        deps: Attribute.new(Label, list: true, default: [], providers: [KotlinJsInfo]),
        kotlin_test_js: Attribute.new(Label, default: "//lib/kotlin:test_js", providers: [KotlinJsInfo]),
        node_runtime: Attribute.new(Label, default: "//lib/node:runtime", providers: [NodeRuntimeInfo]),
        test_runner: Attribute.new(Label, default: "//src/main/kotlin/wake/test:js", providers: [KotlinJsInfo]),
      },
      implementation: ->(context, kotlin_compiler:, srcs:, deps:, kotlin_test_js:, node_runtime:, test_runner:) {
        compiler = kotlin_compiler.fetch(KotlinJsCompilerInfo)
        test_module = compiler.compile(srcs: srcs, deps: [kotlin_test_js, *deps], plugins: [], context: context).find(-> { raise }) { |provider| KotlinJsInfo === provider }

        node = node_runtime.fetch(NodeRuntimeInfo)
        modules = [test_runner.fetch(KotlinJsInfo), test_module].map(&:transitive_runtime_dependencies).flatten.sort.uniq
        script = context.expand_path("%{name}-test-script.js")

        contents = <<~END
          'use strict';
          var kotlin_test = require("kotlin-test");
          var wake_test = require("wake-test-js").org.matthewtodd.wake.test;
          kotlin_test.setAdapter(new wake_test.WakeTest());
          require("#{test_module.require_path}");
        END

        context.run(inputs: [], parameters: [contents], outputs: [script]) do |fs|
          fs.open(script, "wb") { |io| io.write(contents) }
        end

        [TestExecutableInfo.new(
          executable: node.node,
          runfiles: [script, *modules],
          arguments: [script],
          env: { "NODE_PATH" => modules.map { |path| File.join(".", File.dirname(path)) }.uniq.join(":") },
        )]
      },
    )

    registry.new_rule(
      :kt_jvm_lib,
      attributes: {
        kotlin_compiler: Attribute.new(Label, default: "//lib/kotlin:compiler", providers: [KotlinJvmCompilerInfo]),
        srcs: Attribute.new(String, list: true),
        deps: Attribute.new(Label, list: true, providers: [JavaInfo]),
        plugins: Attribute.new(Label, list: true, default: [], providers: [JavaInfo]),
        debug: Attribute.new(TrueClass, default: false),
      },
      implementation: ->(context, kotlin_compiler:, srcs:, deps:, plugins:, debug:) {
        compiler = kotlin_compiler.fetch(KotlinJvmCompilerInfo)
        compiler.compile(srcs: srcs, deps: deps, plugins: plugins, debug: debug && debugging_enabled, context: context)
      },
    )

    registry.new_rule(
      :kt_jvm_test,
      attributes: {
        kotlin_compiler: Attribute.new(Label, default: "//lib/kotlin:compiler", providers: [KotlinJvmCompilerInfo]),
        srcs: Attribute.new(String, list: true),
        deps: Attribute.new(Label, list: true, default: [], providers: [JavaInfo]),
        standard_deps: Attribute.new(Label, list: true, default: ["//lib/kotlin:test", "//lib/kotlin:test_junit5", "//lib/maven/org_junit_jupiter/junit_jupiter_api:jar"], providers: [JavaInfo]),
        java_runtime: Attribute.new(Label, default: "//lib/java:runtime", providers: [JavaRuntimeInfo]),
        test_runner: Attribute.new(Label, default: "//src/main/kotlin/wake/test:junit", providers: [JavaInfo]),
      },
      implementation: ->(context, kotlin_compiler:, srcs:, deps:, standard_deps:, java_runtime:, test_runner:) {
        compiler = kotlin_compiler.fetch(KotlinJvmCompilerInfo)
        test_library = compiler.compile(srcs: srcs, deps: [*deps, *standard_deps], plugins: [], context: context).find(-> { raise }) { |provider| JavaInfo === provider }
        jre = java_runtime.fetch(JavaRuntimeInfo)
        classpath = [test_runner.fetch(JavaInfo), test_library].map(&:transitive_runtime_dependencies).flatten.sort.uniq

        [TestExecutableInfo.new(
          executable: jre.java,
          runfiles: jre.files.concat(classpath),
          arguments: [
            jre.arguments,
            "-cp", classpath.join(":"),
            "org.matthewtodd.wake.test.JUnitLauncherKt", # TODO could pull this into something provided by the test_runner jar.
            test_library.jar,
          ],
          env: {},
        )]
      },
    )

    registry.new_rule(
      :node_runtime,
      attributes: {
        node: Attribute.new(Label, providers: [FileInfo]),
      },
      implementation: ->(context, node:) {
        [NodeRuntimeInfo.new(
          node: node.fetch(FileInfo).path,
        )]
      },
    )

    registry.new_macro(
      :maven_jar,
      attributes: {
        repository: Attribute.new(URI, default: "https://repo1.maven.org/maven2"),
        artifact: Attribute.new(MavenCoordinates),
        sha256: Attribute.new(Verifier),
      },
      implementation: ->(context, repository:, artifact:, sha256:) {
        context.package(artifact.package_path) do
          http_file(
            name: artifact.filename,
            url: artifact.url(repository),
            sha256: sha256,
          )

          java_import(
            name: "jar",
            jar: artifact.filename,
          )
        end
      },
    )

    registry.new_macro(
      :maven_kt_js_jar,
      attributes: {
        repository: Attribute.new(URI, default: "https://repo1.maven.org/maven2"),
        artifact: Attribute.new(MavenCoordinates),
        sha256: Attribute.new(Verifier),
        js_path: Attribute.new(String),
      },
      implementation: ->(context, repository:, artifact:, sha256:, js_path:) {
        context.package(artifact.package_path) do
          http_file(
            name: artifact.filename,
            url: artifact.url(repository),
            sha256: sha256,
          )

          kt_js_import(
            name: "jar",
            jar: artifact.filename,
            js_path: js_path,
          )
        end
      },
    )
  end

  if Kernel.const_defined? :Minitest
    Test = Minitest::Test
  else
    Test = Object
  end

  class Context
    def initialize(actions, providers, label)
      @actions = actions
      @providers = providers
      @label = label
    end

    def invoke(rule, attributes)
      # TODO do we want rules to register providers more explicitly?
      @providers[@label] = rule.call(self, **attributes.using(@providers)) || []
    end

    def expand_path(path)
      File.join(@label.package, path.gsub("%{name}", @label.name))
    end

    def run(inputs: [], parameters: [], outputs:, &block)
      @actions.run(@label, inputs: inputs, parameters: parameters, outputs: outputs, &block)
    end
  end

  class Actions
    def initialize(console, fs)
      @console = console
      @fs = fs
    end

    def run(label, inputs: [], parameters: [], outputs:, &block)
      alien = outputs.reject { |path| path.start_with?(label.package) }
      raise "Action for #{label} cannot produce outputs outside of #{label.package}, but claims #{alien}." if alien.any?

      key = Digest::SHA256.hexdigest("#{label}-#{inputs.map { |path| checksum(path) }.join("-")}-#{parameters.join("-")}-#{outputs.join("-")}")

      if !@fs.exists?("var/cache/#{key}")
        @fs.mktmpdir do |dir|
          inputs.each do |path|
            if @fs.exists?(path)
              @fs.link(path, "#{dir}/#{path}")
            else
              @fs.link("var/tmp/#{path}", "#{dir}/#{path}")
            end
          end

          block.call(@fs.sandbox(dir))

          missing = outputs.reject { |path| @fs.exists?("#{dir}/#{path}") }
          raise "Action for #{label} failed to produce outputs #{missing}." if missing.any?

          outputs.each do |path|
            @fs.link("#{dir}/#{path}", "var/cache/#{key}/#{path}")
          end
        end
      end

      outputs.each do |path|
        @fs.link("var/cache/#{key}/#{path}", "var/tmp/#{path}")
      end
    end

    def expire(before:)
      @fs.purge("var/cache", before: before)
    end

    private

    def checksum(path)
      if @fs.exists?(path)
        @fs.checksum(path)
      else
        @fs.checksum("var/tmp/#{path}")
      end
    end
  end

  class ActionsTest < Test
    def setup
      @files = {}
      @actions = Actions.new(Console.new(StringIO.new), InMemoryFilesystem.new("/workspace", @files))
    end

    def test_run_caching
      @files["/workspace/src/foo.txt"] = "FOO"
      @files["/workspace/src/bar.txt"] = "BAR"

      @actions.run(Label["//src:baz"], outputs: ["src/baz.out"]) do |fs|
        fs.open("src/baz.out", "w") { |io| io.puts("BAZ") }
      end

      @actions.run(Label["//src:foo"], inputs: ["src/foo.txt", "src/bar.txt", "src/baz.out"], outputs: ["src/foo.out"]) do |fs|
        fs.open("src/foo.out", "w") do |io|
          2.times { fs.open("src/foo.txt", "r") { |foo| io.puts(foo.read) } }
          2.times { fs.open("src/bar.txt", "r") { |bar| io.puts(bar.read) } }
          2.times { fs.open("src/baz.out", "r") { |baz| io.puts(baz.read) } }
        end
      end

      assert_equal(<<~END, @files.fetch("/workspace/var/tmp/src/foo.out"))
        FOO
        FOO
        BAR
        BAR
        BAZ
        BAZ
      END

      # nothing changes (re-run with raising block?)
      @actions.run(Label["//src:foo"], inputs: ["src/foo.txt", "src/bar.txt", "src/baz.out"], outputs: ["src/foo.out"]) do |fs|
        raise "Shouldn't get here!"
      end

      # source changes
      @files["/workspace/src/foo.txt"] = "FOOFOO"

      @actions.run(Label["//src:foo"], inputs: ["src/foo.txt", "src/bar.txt", "src/baz.out"], outputs: ["src/foo.out"]) do |fs|
        fs.open("src/foo.out", "w") do |io|
          2.times { fs.open("src/foo.txt", "r") { |foo| io.puts(foo.read) } }
          2.times { fs.open("src/bar.txt", "r") { |bar| io.puts(bar.read) } }
          2.times { fs.open("src/baz.out", "r") { |baz| io.puts(baz.read) } }
        end
      end

      assert_equal(<<~END, @files.fetch("/workspace/var/tmp/src/foo.out"))
        FOOFOO
        FOOFOO
        BAR
        BAR
        BAZ
        BAZ
      END

      # generated changes
      @actions.run(Label["//src:baz"], parameters: [:changed], outputs: ["src/baz.out"]) do |fs|
        fs.open("src/baz.out", "w") { |io| io.puts("BAZBAZ") }
      end

      @actions.run(Label["//src:foo"], inputs: ["src/foo.txt", "src/bar.txt", "src/baz.out"], outputs: ["src/foo.out"]) do |fs|
        fs.open("src/foo.out", "w") do |io|
          2.times { fs.open("src/foo.txt", "r") { |foo| io.puts(foo.read) } }
          2.times { fs.open("src/bar.txt", "r") { |bar| io.puts(bar.read) } }
          2.times { fs.open("src/baz.out", "r") { |baz| io.puts(baz.read) } }
        end
      end

      assert_equal(<<~END, @files.fetch("/workspace/var/tmp/src/foo.out"))
        FOOFOO
        FOOFOO
        BAR
        BAR
        BAZBAZ
        BAZBAZ
      END
    end
  end

  class InMemoryFilesystem
    def initialize(base, files)
      @base = base
      @files = files
    end

    def checksum(path)
      # A real filesystem would do some caching here, since these are expensive.
      Digest::SHA256.hexdigest(@files.fetch(absolute_path(path)))
    end

    def exists?(path)
      # First clause is for files.
      # Second clause is a hack for directories, since we're not modeling them fully, just putting path -> contents in a Hash.
      path = absolute_path(path)
      @files.key?(path) || @files.keys.any? { |candidate| candidate.start_with?(path) && candidate[path.length] == "/" }
    end

    def link(src, dest)
      @files[absolute_path(dest)] = @files.fetch(absolute_path(src))
    end

    def mktmpdir(&block)
      tmp = "/tmp/#{Time.now.strftime("%Y%m%d")}-#{$$}-#{rand(0x100000000).to_s(36)}"
      yield tmp
    ensure
      @files.delete_if { |path, content| path.start_with?(tmp) }
    end

    def sandbox(base)
      Sandbox.new(absolute_path(base), @files)
    end

    private

    def absolute_path(path)
      path.start_with?("/") ? path : "#{@base}/#{path}"
    end

    class Sandbox
      def initialize(base, files)
        @base = base
        @files = files
      end

      def open(path, mode, permissions: 0644, &block)
        case mode
        when "r"
          yield StringIO.new(@files.fetch(File.join(@base, path)))
        when "w"
          io = StringIO.new
          yield io
          @files[File.join(@base, path)] = io.string
        else
          raise "Unsupported mode #{mode}"
        end
      end

      def exec!(*args)
        raise "InMemoryFilesystem::Sandbox doesn't support exec!"
      end

      def mktmpdir(&block)
        raise "InMemoryFilesystem::Sandbox doesn't support mktmpdir!"
      end
    end
  end

  class RealFilesystem
    def initialize(base)
      @base = base
      path = absolute_path("var/run/filesystem.yml")
      cache = Psych.load_file(path) rescue Hash.new
      @checksums = cache.fetch(:checksums, {})
      @mtimes = cache.fetch(:mtimes, {})
      @mutex = Mutex.new
      at_exit {
        cache = { checksums: @checksums, mtimes: @mtimes }
        FileUtils.mkdir_p(File.dirname(path))
        File.open(path, "wb") { |io| Psych.dump(cache, io) }
      }
    end

    def checksum(path)
      path = absolute_path(path)

      # TODO if these stats get expensive, maybe we eagerly cache checksums for
      # generated files and take a separate path for "volatile" source files.
      mtime = File.mtime(path)

      @mutex.synchronize do
        if @mtimes.key?(path) && @mtimes[path] == mtime
          @checksums.fetch(path)
        else
          @mtimes[path] = mtime
          @checksums[path] = Digest::SHA256.file(path).hexdigest
        end
      end
    end

    def exists?(path)
      path = absolute_path(path)
      File.exist?(path)
    end

    def link(src, dest)
      src = absolute_path(src)
      dest = absolute_path(dest)
      FileUtils.mkdir_p(File.dirname(dest))
      FileUtils.ln(src, dest, force: true)
    end

    def purge(path, before:)
      path = absolute_path(path)

      Find.find(path).
        map { |p| [p, File.stat(p)] }.
        select { |p, stat| stat.file? }.
        select { |p, stat| stat.mtime < before }.
        select { |p, stat| stat.nlink == 1 }.
        each { |p, stat| FileUtils.remove_entry(p) }

      Find.find(path).
        select { |p| File.directory?(p) }.
        sort.
        reverse_each { |p| FileUtils.remove_entry(p) if Dir.empty?(p) }
    end

    def mktmpdir(&block)
      Dir.mktmpdir(&block)
    end

    def sandbox(base)
      Sandbox.new(self, absolute_path(base))
    end

    private

    def absolute_path(path)
      path.start_with?("/") ? path : "#{@base}/#{path}"
    end

    class Sandbox
      def initialize(fs, base)
        @fs = fs
        @base = base
      end

      def open(path, mode, permissions: 0644, &block)
        path = File.join(@base, path)
        FileUtils.mkdir_p(File.dirname(path))
        File.open(path, mode, permissions) { |io| io.sync = true; block.call(io) }
      end

      def exec!(*args, out: StringIO.new, err: StringIO.new, env: {})
        spy_out = StringIO.new
        spy_err = StringIO.new

        initial_files = Find.find(@base).
          reject { |path| File.directory?(path) }.
          map { |path| path[@base.length + 1, path.length - 1] }

        args = args.flatten.map { |a| a.gsub("%{pwd}", @base) }
        env = env.map { |k, v| [k, v.gsub("%{pwd}", @base)] }.to_h
        status = exec(*args, out: CompositeIO.new(out, spy_out), err: CompositeIO.new(err, spy_err), env: env)

        if !status.success?
          files = Find.find(@base).
            reject { |path| File.directory?(path) }.
            map { |path| path[@base.length + 1, path.length - 1] }
          raise ExecutionError.new(args: args, status: status, out: spy_out.string, err: spy_err.string, env: env, pwd: @base, files: files, initial_files: initial_files)
        end
      end

      def mktmpdir(&block)
        @fs.mktmpdir(&block)
      end

      private

      def exec(*args, out: StringIO.new, err: StringIO.new, env: {})
        Open3.popen3(env, *args.flatten, chdir: @base, unsetenv_others: true) do |i, o, e, t|
          i.close
          out_reader = Thread.new { IO.copy_stream(o, out) }
          err_reader = Thread.new { IO.copy_stream(e, err) }
          out_reader.join
          err_reader.join
          t.value
        end
      end

      class ExecutionError < RuntimeError
        attr_reader :status
        attr_reader :out
        attr_reader :err
        attr_reader :env

        def initialize(args:, status:, out:, err:, env:, pwd:, files:, initial_files:)
          @args = args
          @status = status
          @out = out
          @err = err
          @env = env
          @files = files

          added_files = (@files.to_set - initial_files.to_set).to_a

          super(<<~END)
            Commmand exited with status #{status.exitstatus}.

            COMMAND:
            #{Shellwords.join(args)}

            ENV:
            #{env.map { |k, v| "#{k}=#{v}" }.join("\n")}

            PWD:
            #{pwd}

            FILES:
            #{files.sort.join("\n")}

            ADDED FILES:
            #{added_files.sort.join("\n")}

            OUT:
            #{out.strip}

            ERR:
            #{err.strip}
          END
        end
      end
    end
  end

  class RealFilesystemTest < Test
    def setup; @tmp = Dir.mktmpdir; end
    def teardown; FileUtils.remove_entry(@tmp); end

    def test_exec
      fs = RealFilesystem.new(@tmp)
      sandbox = fs.sandbox("sandbox")
      sandbox.open("foo.txt", "wb") do |io|
        sandbox.exec!("bash", "-c", "echo hi", out: io)
      end
      assert_equal "hi\n", File.read(File.join(@tmp, "sandbox", "foo.txt"))
    end

    def test_exec_raises
      fs = RealFilesystem.new(@tmp)
      sandbox = fs.sandbox("sandbox")
      # We don't care what happens to the file (was it partially written?)
      # because we're typically making sandboxes in tmpdirs that get thrown
      # away anyway.
      sandbox.open("foo.txt", "wb") do |io|
        error = assert_raises(Wake::RealFilesystem::Sandbox::ExecutionError) do
          sandbox.exec!("bash", "-c", "echo hi; false", out: io)
        end
        assert_equal "hi\n", error.out
        assert_equal "", error.err
      end
    end
  end

  class ProviderRegistry
    class MissingLabelError < KeyError
      def initialize(label)
        super "#{label} has not been seen"
      end
    end

    class MissingProviderError < KeyError
      def initialize(label, type)
        super "#{label} does not provide #{type}"
      end
    end

    def initialize
      @providers = {}
      @mutex = Mutex.new
    end

    def [](label, types)
      @providers.fetch(label) { raise MissingLabelError.new(label) }.slice(types)
    end

    def []=(label, providers)
      @mutex.synchronize do
        @providers[label] = Holder.new(label, providers)
      end
    end

    def of(type)
      @providers.
        select { |label, providers| providers.key?(type) }.
        map { |label, providers| [label, providers.fetch(type)] }.
        to_h
    end

    private

    class Holder
      def initialize(label, providers)
        @label = label
        @providers = providers.map { |instance| [instance.class, instance] }.to_h.freeze
      end

      def fetch(type)
        @providers.fetch(type) { raise MissingProviderError.new(@label, type) }
      end

      def key?(type)
        @providers.key?(type)
      end

      def slice(types)
        Holder.new(@label, @providers.fetch_values(*types) { |missing| raise MissingProviderError.new(@label, missing) })
      end
    end
  end

  class ProviderRegistryTest < Test
    def setup
      @registry = ProviderRegistry.new
      @label = Label["//src/main:foo"]
      @type = Class.new
      @instance = @type.new
    end

    def test_happy_path
      @registry[@label] = [@instance]
      assert_equal @instance, @registry[@label, [@type]].fetch(@type)
    end

    def test_upstream_does_not_exist
      assert_raises(ProviderRegistry::MissingLabelError) do
        @registry[@label, [@type]]
      end
    end

    def test_upstream_does_not_provide
      @registry[@label] = []
      assert_raises(ProviderRegistry::MissingProviderError) do
        @registry[@label, [@type]]
      end
    end

    def test_current_does_not_depend
      @registry[@label] = [@instance]
      providers = @registry[@label, []]
      assert_raises(ProviderRegistry::MissingProviderError) do
        providers.fetch(@type)
      end
    end
  end

  class Verifier
    def self.parse(checksum)
      Verifier.new(Digest::SHA256, checksum: checksum)
    end

    def initialize(digest, checksum: nil, observer: ->(measured_checksum) { })
      @digest = digest
      @expected_checksum = checksum
      @observer = observer
    end

    def checksum
      @expected_checksum
    end

    def observing(&observer)
      Verifier.new(@digest, checksum: @expected_checksum, observer: observer)
    end

    def wrapping(path, io, &block)
      digest = @digest.new
      block.call(Wrapper.new(io, digest))
      measured_checksum = digest.hexdigest
      if @expected_checksum
        raise "Expected #{@expected_checksum} for #{path} but got #{measured_checksum}" if @expected_checksum != measured_checksum
      else
        @observer.call(measured_checksum)
      end
    end

    private

    class Wrapper
      def initialize(io, digest)
        @io = io
        @digest = digest
      end

      def write(content)
        @digest.update(content)
        @io.write(content)
      end
    end
  end

  class Platform
    def initialize(host_os:)
      @host_os = host_os
    end

    def host_os
      case @host_os
      when /darwin/
        :macos
      when /linux/
        :linux
      end
    end
  end

  class PlatformTest < Test
    def test_host_os_darwin_macos
      assert_equal :macos, Platform.new(host_os: "darwin19").host_os
    end

    def test_host_os_linux_linux
      assert_equal :linux, Platform.new(host_os: "i686-linux").host_os
    end
  end

  class Registry
    def initialize
      @dsl = Class.new(Dsl)
      @targets = {}
      @toolchains = []
      @toolchain_types = {}
    end

    def new_package(package)
      @dsl.new(registry: self, package: package)
    end

    def new_rule(rule_name, attributes: {}, implementation: ->(context, **attributes) { })
      schema = AttributeSchema.new(attributes)

      @dsl.class_eval(<<~END)
        def #{rule_name}(#{schema.dsl_method_parameters(:name)})
          __#{rule_name}(#{schema.dsl_method_forwarding_parameters(:name)})
        end
      END

      @dsl.define_method("__#{rule_name}") do |name:, **attributes|
        @registry.new_target(
          label: Label.new(package: @package, name: name),
          rule: implementation,
          attributes: schema.parse(attributes, package: @package),
        )
      end

      @dsl.class_eval("private :__#{rule_name}")
    end

    def new_target(label:, rule:, attributes:)
      @targets[label] = Target.new(rule: rule, attributes: attributes)
    end

    def new_toolchain_type(package:, name:, providers:)
      @toolchain_types[Label.new(package: package, name: name)] = providers
    end

    def new_toolchain(package:, name:, os:, toolchain:, toolchain_type:)
      @toolchains << Toolchain.new(
        os: os,
        toolchain: Label.parse(toolchain, package: package),
        toolchain_type: Label.parse(toolchain_type, package: package),
      )
    end

    def new_macro(macro_name, attributes: {}, implementation: ->(context, **attributes) { })
      schema = AttributeSchema.new(attributes)

      @dsl.class_eval(<<~END)
        def #{macro_name}(#{schema.dsl_method_parameters})
          __#{macro_name}(#{schema.dsl_method_forwarding_parameters})
        end
      END

      @dsl.define_method("__#{macro_name}") do |**attributes|
        @registry.expand_macro(
          package: @package,
          macro: implementation,
          attributes: schema.parse(attributes, package: @package),
        )
      end

      @dsl.class_eval("private :__#{macro_name}")
    end

    def expand_macro(package:, macro:, attributes:)
      macro.call(MacroContext.new(registry: self, package: package), **attributes)
    end

    # TODO reshape Platform to be easy to stub with something from the stdlib.
    def resolve(platform:)
      result = @targets.dup

      # TODO lazily include toolchains as we will repository targets!
      # So, don't bother with //lib/java:compiler unless one of my targets depends on it.
      @toolchains.select { |toolchain| toolchain.supports?(platform) }.each do |toolchain|
        providers = @toolchain_types.fetch(toolchain.toolchain_type)

        result[toolchain.toolchain_type] = Target.new(
          attributes: AttributeSchema.new(
            actual: Attribute.new(Label, providers: providers),
          ).parse({
            actual: toolchain.toolchain,
          }),
          rule: ->(context, actual:) {
            providers.map { |provider| actual.fetch(provider) }
          },
        )
      end

      result.freeze
    end

    private

    class Dsl
      def initialize(registry:, package:)
        @registry = registry
        @package = package
      end

      def toolchain_type(name:, providers: [])
        @registry.new_toolchain_type(package: @package, name: name, providers: providers)
      end

      def toolchain(name:, os:, toolchain:, toolchain_type:)
        @registry.new_toolchain(package: @package, name: name, os: os, toolchain: toolchain, toolchain_type: toolchain_type)
      end
    end

    class MacroContext
      def initialize(registry:, package:)
        @registry = registry
        @package = package
      end

      def package(name, &block)
        @registry.new_package([@package, name].join("/")).instance_exec(&block)
      end
    end

    class Toolchain < Struct.new(:os, :toolchain, :toolchain_type, keyword_init: true)
      def supports?(platform)
        os == platform.host_os
      end
    end
  end

  class RegistryTest < Test
    def test_platform_constraints_for_toolchains
      registry = Registry.new

      registry.new_rule(:foo_compiler)

      registry.new_macro(
        :foo_compiler_package,
        attributes: {
          name: Attribute.new(String),
        },
        implementation: ->(context, name:) {
          context.package(name) {
            foo_compiler(name: "compiler")
          }
        },
      )

      registry.new_package("foo").instance_exec do
        toolchain_type(name: "compiler")

        foo_compiler_package(name: "linux")
        foo_compiler_package(name: "macos")

        toolchain(
          name: "compiler_linux",
          os: :linux,
          toolchain: "//foo/linux:compiler",
          toolchain_type: "//foo:compiler",
        )

        toolchain(
          name: "compiler_macos",
          os: :macos,
          toolchain: "//foo/macos:compiler",
          toolchain_type: "//foo:compiler",
        )
      end

      linux_targets = registry.resolve(
        platform: Platform.new(host_os: "i686-linux"),
      )

      macos_targets = registry.resolve(
        platform: Platform.new(host_os: "darwin19"),
      )

      assert_equal Set[Label["//foo/linux:compiler"]],
        linux_targets[Label["//foo:compiler"]].dependencies

      assert_equal Set[Label["//foo/macos:compiler"]],
        macos_targets[Label["//foo:compiler"]].dependencies
    end
  end

  class Console
    def initialize(io)
      @events = Queue.new
      @renderings = Queue.new

      cols = io.tty? ? io.winsize[1] : 80

      @ticker = Thread.new do
        while true
          @events << [:tick, Process.clock_gettime(Process::CLOCK_MONOTONIC)]
          sleep 0.1
        end
      end

      @renderer = Thread.new(cols) do |cols|
        time = Process.clock_gettime(Process::CLOCK_MONOTONIC)
        targets = []
        progress = {}
        test_results = []
        arbitrary_output = []

        while event = @events.pop
          case event.first
          when :arbitrary_output
            arbitrary_output << event[1..-1]
          when :progress
            progress[event[1]] = event[2]
          when :target_invocation
            targets << { label: event.last, started_at: time }
          when :target_completion
            targets.delete_if { |target| target.fetch(:label) == event.last }
          when :test_result
            test_results << event.last
          when :tick
            time = event.last
          end

          @renderings << View.new(
            time: time,
            targets: targets,
            progress: progress,
            test_results: test_results,
            arbitrary_output: arbitrary_output,
          ).format(cols: cols)
        end
      end

      @blatter = Thread.new(io, cols) do |io, cols|
        previous = ""

        while buffer = @renderings.pop
          unless previous.empty?
            row_count = previous.
              gsub(/\e\[.*?m/, ""). # strip non-printing ANSI escape codes
              gsub(/(.{#{cols}})(.)/, "\\1\n\\2"). # wrap long lines; careful! rows of exactly cols columns shouldn't wrap
              count("\n")
            io.write("\e[#{row_count}F")
            io.write("\e[J")
          end

          io.write(buffer)
          io.flush
          previous = buffer
        end
      end
    end

    def join
      @ticker.exit
      @events.close
      @renderer.join
      @renderings.close
      @blatter.join
    end

    def write(*args)
      @events << [:arbitrary_output, *args]
    end

    def puts(*args)
      write(*args.
        map(&:to_s).
        map(&:chomp).
        map { |a| a.concat("\n") })
    end

    def flush
      # no-op for now; all ops redraw
    end

    def report_target_invocation(label)
      @events << [:target_invocation, label]
    end

    def report_target_completion(label)
      @events << [:target_completion, label]
    end

    def report_progress(label, percentage)
      @events << [:progress, label, percentage]
    end

    def report_test_result(result)
      @events << [:test_result, result]
    end

    private

    class View
      def initialize(time:, targets:, progress:, test_results:, arbitrary_output:)
        @time = time.freeze
        @targets = targets.dup.freeze
        @progress = progress.select { |label, progress| progress < 100 }.dup.freeze
        @test_results = test_results.dup.freeze
        @arbitrary_output = arbitrary_output.dup.freeze
      end

      def format(cols:)
        buffer = StringIO.new

        if @targets.any?
          @targets.each do |target|
            label = target.fetch(:label)
            running_time = @time - target.fetch(:started_at)
            buffer.puts "%s %ds" % [label, running_time]
          end
          buffer.puts
        end

        if @progress.any?
          format = "%s |%s%s| %2d%%"
          @progress.each do |label, percentage|
            total_cols = cols - (format % [label, "", "", percentage]).length
            bar_cols = (percentage * total_cols / 100.0).floor
            space_cols = total_cols - bar_cols
            buffer.puts format % [label, "=" * bar_cols, " " * space_cols, percentage]
          end
          buffer.puts
        end

        if @test_results.any?
          buffer.print("\e[7;%sm" % [@test_results.max.ansi_color_code])
          buffer.print " " * @test_results.count
          buffer.puts "\e[0m"
          buffer.puts

          @test_results.reject(&:passed?).each_with_index do |result, i|
            buffer.puts "\e[%sm%3d) %s:\n%s\e[0m" % [result.ansi_color_code, i + 1, result.result_label, result]
            buffer.puts
          end
        end

        if @arbitrary_output.any?
          @arbitrary_output.each do |args|
            buffer.puts(*args)
          end

          buffer.puts
        end

        buffer.string
      end
    end
  end

  # TODO connection pool?
  # TODO worker pool?
  # TODO "integration" test?
  class HttpDownloader
    def initialize(console = nil)
      @console = console
    end

    def get(url, io, original: url)
      Net::HTTP.get_response(url) do |response|
        case response
        when Net::HTTPSuccess
          response.read_body(CompositeIO.new(io, Progress.new(@console, original, response["content-length"].to_i)))
        when Net::HTTPRedirection
          get(URI.parse(response["location"]), io, original: original)
        else
          response.error!
        end
      end
    end

    private

    class Progress
      def initialize(console, url, total)
        @console = console
        @label = url.path.split("/").last
        @total = total
        @current = 0
      end

      def write(chunk)
        @current += chunk.size
        @console.report_progress(@label, (@current * 100.0 / @total).floor)
        chunk.size
      end
    end
  end

  class CompositeIO
    def initialize(*ios)
      @ios = ios
    end

    def write(*args)
      # TODO this gets hinky when the answers are different!
      @ios.map { |io| io.write(*args) }.max
    end

    def <<(*args)
      write(*args)
    end
  end

  # Struct saves the boilerplate of making Label work as a Hash key.
  class Label < Struct.new(:package, :name, keyword_init: true)
    def self.[](string)
      parse(string)
    end

    def self.parse(string, package: nil)
      head, rest = string.split(":", 2)

      if head.start_with? "//"
        parsed_package = head[2..-1]
        parsed_name = rest
      elsif rest
        parsed_package = package
        parsed_name = rest
      else
        parsed_package = package
        parsed_name = head
      end

      if parsed_package.nil? || parsed_name.nil?
        raise "Invalid label: #{string.inspect}"
      end

      Label.new(package: parsed_package, name: parsed_name).freeze
    end

    def inspect
      "#<label #{to_s}>"
    end

    def to_s
      "//#{package}:#{name}"
    end
  end

  class LabelTest < Test
    def test_parse
      label = Label.parse("//src/main:foo")
      assert_equal "src/main", label.package
      assert_equal "foo", label.name
    end

    def test_parse_without_name
      assert_raises { Label.parse("//src/main") }
    end

    def test_parse_relative
      label = Label.parse(":foo", package: "src/main")
      assert_equal "src/main", label.package
      assert_equal "foo", label.name
    end

    def test_parse_relative_without_package
      assert_raises { Label.parse(":foo") }
    end

    def test_parse_filename
      label = Label.parse("foo.kt", package: "src/main")
      assert_equal "src/main", label.package
      assert_equal "foo.kt", label.name
    end
  end

  class Target
    def initialize(rule:, attributes:)
      @rule = rule
      @attributes = attributes
    end

    def dependencies
      @attributes.dependencies
    end

    def invoke(context)
      context.invoke(@rule, @attributes)
    end
  end

  class TargetTest < Test
    def test_dependencies
      target = Target.new(
        rule: ->(context, **attributes) { },
        attributes: AttributeSchema.new(
          thing: Attribute.new(Label),
          things: Attribute.new(Label, list: true),
          irrelevant_things: Attribute.new(String, list: true),
        ).parse({
          thing: "//src/main:quux",
          things: [
            "//src/main:bar",
            "//src/main:baz",
          ],
          irrelevant_things: [
            "a.rb",
            "b.rb",
          ],
        }),
      )
      assert_equal [
        Label["//src/main:bar"],
        Label["//src/main:baz"],
        Label["//src/main:quux"],
      ].to_set, target.dependencies
    end
  end

  class AttributeSchema
    def initialize(fields = {})
      @fields = fields
    end

    def dependencies(values)
      @fields.map { |name, type| type.dependencies(values.fetch(name)) }.reduce(Set.new, &:merge).freeze
    end

    def dsl_method_parameters(prefix = nil)
      extra = prefix ? ["#{prefix}:"] : []
      extra.concat(@fields.map { |name, type| type.as_method_parameter(name) }).join(", ")
    end

    def dsl_method_forwarding_parameters(prefix = nil)
      extra = prefix ? ["#{prefix}: #{prefix}"] : []
      extra.concat(@fields.keys.map { |name| "#{name}: #{name}" }).join(", ")
    end

    def parse(raw, **options)
      Attributes.new(self, values(raw, **options))
    end

    def using(providers, values)
      @fields.map { |name, type| [name, type.using(providers, values.fetch(name))] }.to_h.freeze
    end

    private

    def values(raw, **options)
      @fields.map { |name, type| [name, type.parse(raw[name], **options)] }.to_h.freeze
    end
  end

  class AttributeSchemaTest < Test
    def test_dsl_method_parameters
      schema = AttributeSchema.new(
        deps: Attribute.new(Label, list: true),
        compiler: Attribute.new(Label, default: "//lib:compiler"),
        strip_components: Attribute.new(PathCleaner, default: 0),
        build: Attribute.new(Proc, default: ->() { }),
        neverlink: Attribute.new(TrueClass, default: false),
      )
      assert_equal "name:, deps:, compiler: \"//lib:compiler\", strip_components: 0, build: ->() { }, neverlink: false", schema.dsl_method_parameters(:name)
    end

    def test_dsl_method_forwarding_parameters
      schema = AttributeSchema.new(
        deps: Attribute.new(Label),
        compiler: Attribute.new(Label),
      )
      assert_equal "name: name, deps: deps, compiler: compiler", schema.dsl_method_forwarding_parameters(:name)
    end
  end

  class Attributes
    def initialize(schema, values)
      @schema = schema
      @values = values
    end

    def dependencies
      @schema.dependencies(@values)
    end

    def using(providers)
      @schema.using(providers, @values)
    end

    def to_hash
      @values
    end
  end

  class Attribute
    def initialize(type, list: false, default: nil, providers: [])
      @type = type
      @list = list
      @default = default
      @providers = providers
    end

    def as_method_parameter(name)
      !@default.nil? ? "#{name}: #{@type == Proc ? "->() { }" : @default.inspect}" : "#{name}:"
    end

    def dependencies(value)
      @type == Label ? (@list ? Set.new(value) : Set.new([value])) : Set.new
    end

    def parse(raw_value, **options)
      if @list
        Array(raw_value || @default).map { |item| try_parse(item, **options) }.freeze
      else
        try_parse(raw_value || @default, **options).freeze
      end
    end

    def using(providers, value)
      if @type == Label && !@list
        providers[value, @providers]
      elsif @type == Label && @list
        value.map { |v| providers[v, @providers] }
      else
        value
      end
    end

    private

    def try_parse(raw_value, **options)
      if @type === raw_value
        raw_value
      elsif @type == Label
        @type.parse(raw_value, **options)
      elsif @type == TrueClass && raw_value == false
        raw_value
      else
        @type.parse(raw_value)
      end
    end
  end

  class AttributeTest < Test
    def test_parse
      assert_equal URI.parse("https://example.com"), Attribute.new(URI).parse("https://example.com")
      assert Attribute.new(TrueClass).parse(true)
    end

    def test_parse_already_parsed
      assert_equal URI.parse("https://example.com"), Attribute.new(URI).parse(URI.parse("https://example.com"))
    end

    def test_parse_default
      assert_equal URI.parse("https://example.com"), Attribute.new(URI, default: "https://example.com").parse(nil)
      assert Attribute.new(TrueClass, default: true).parse(nil)
      assert !Attribute.new(TrueClass, default: false).parse(nil)
    end

    def test_parse_nil_no_default
      # TODO make the error messages better. Requires attribute to know or be passed its name, which we're not doing yet.
      assert_raises { Attribute.new(Label).parse(nil) }
      assert_raises { Attribute.new(MavenCoordinates).parse(nil) }
      assert_raises { Attribute.new(String).parse(nil) }
      assert_raises { Attribute.new(TrueClass).parse(nil) }
      assert_raises { Attribute.new(URI).parse(nil) }
    end

    def test_parse_list
      assert_equal [URI.parse("https://example.com")], Attribute.new(URI, list: true).parse(["https://example.com"])
    end

    def test_parse_list_single
      assert_equal [URI.parse("https://example.com")], Attribute.new(URI, list: true).parse("https://example.com")
    end

    def test_parse_list_empty
      assert_equal [], Attribute.new(URI, list: true).parse(nil)
    end

    def test_parse_relative_label
      assert_equal Label["//src/main:foo"], Attribute.new(Label).parse(":foo", package: "src/main")
    end
  end

  class Extractor
    def self.parse(key)
      Extractor.new(key)
    end

    def initialize(format)
      @format = format
    end

    def extract(io, strip_components:, &collector)
      extractor(strip_components).call(nil, io) do |entry_path, entry_io|
        collector.call(entry_path, entry_io)
      end
    end

    def to_s
      "Extractor(#{@format})"
    end

    private

    def extractor(strip_components)
      case @format
      when :tar_gz
        Gzip.new(Tar.new(strip_components))
      when :zip
        Zip.new(strip_components)
      else
        raise "Unsupported Extractor #{@format}"
      end
    end
  end

  class Gzip
    def initialize(delegate)
      @delegate = delegate
    end

    def call(name, io, &collector)
      Zlib::GzipReader.wrap(io) do |gz|
        @delegate.call(name, gz, &collector)
      end
    end
  end

  class GzipTest < Test
    def test_extracts_content
      contents = ""

      StringIO.open(contents) do |io|
        Zlib::GzipWriter.wrap(io) do |gz|
          gz.write("Hello!")
        end
      end

      entries = {}
      gzip = Gzip.new(PathCleaner.new(strip_components: 0))
      gzip.call("file.txt", StringIO.new(contents)) { |path, io|
        entries[path] = io.read
      }

      assert_equal ["file.txt"], entries.keys
      assert_equal "Hello!", entries["file.txt"]
    end
  end

  class Tar
    def initialize(delegate)
      @delegate = delegate
    end

    def call(_, io, &collector)
      Gem::Package::TarReader.new(io) do |tar|
        tar.each do |entry|
          @delegate.call(entry.full_name, entry, &collector) if entry.file?
        end
      end
    end
  end

  class TarTest < Test
    def test_extracts_files
      contents = ""

      StringIO.open(contents) do |io|
        Gem::Package::TarWriter.new(io) do |tar|
          tar.add_file_simple("file.txt", 0644, 6) do |file|
            file.write("Hello!")
          end
        end
      end

      entries = {}
      tar = Tar.new(PathCleaner.new(strip_components: 0))
      tar.call(nil, StringIO.new(contents)) { |path, io| entries[path] = io.read }
      assert_equal ["file.txt"], entries.keys
      assert_equal "Hello!", entries["file.txt"]
    end

    def test_skips_directories
      contents = ""

      StringIO.open(contents) do |io|
        Gem::Package::TarWriter.new(io) do |tar|
          tar.mkdir("other", 0755)
        end
      end

      entries = {}
      tar = Tar.new(PathCleaner.new(strip_components: 0))
      tar.call(nil, StringIO.new(contents)) { |path, io| entries[path] = io.read }
      assert_equal [], entries.keys
    end
  end

  class Zip
    def initialize(delegate)
      @delegate = delegate
    end

    def call(name, io, &collector)
      Reader.new(io).each do |name, io|
        @delegate.call(name, io, &collector)
      end
    end

    # https://en.wikipedia.org/wiki/Zip_(file_format)
    class Reader
      MAX_END_OF_CDS_SIZE = 65_536 + 18
      END_OF_CDS = [0x06054b50].pack("V")
      CDIR_ENTRY_STATIC_HEADER_LENGTH = 46
      LOCAL_ENTRY_STATIC_HEADER_LENGTH = 30

      def initialize(io)
        @io = io
      end

      def each(&block)
        begin
          @io.seek(-MAX_END_OF_CDS_SIZE, IO::SEEK_END)
        rescue Errno::EINVAL
          @io.seek(0, IO::SEEK_SET)
        end

        buffer = @io.read
        record = EndOfCentralDirectoryRecord.parse(buffer[buffer.rindex(END_OF_CDS)..-1])

        @io.seek(record.offset, IO::SEEK_SET)

        headers = record.size.times.map do
          header = CentralDirectoryFileHeader.parse(@io.read(CDIR_ENTRY_STATIC_HEADER_LENGTH))
          header.file_name = @io.read(header.file_name_length)
          header.extra_field = @io.read(header.extra_field_length)
          header.file_comment = @io.read(header.file_comment_length)
          header.freeze
        end

        headers.select(&:file?).each do |header|
          @io.seek(header.offset)

          local = LocalFileHeader.parse(@io.read(LOCAL_ENTRY_STATIC_HEADER_LENGTH))
          local.file_name = @io.read(local.file_name_length)
          local.extra_field = @io.read(local.extra_field_length)
          local.freeze

          block.call local.file_name, local.decompress(@io)
        end
      end

      class EndOfCentralDirectoryRecord < Struct.new(
        :end_of_central_directory_signature,
        :number_of_this_disk,
        :disk_where_central_directory_starts,
        :number_of_central_directory_records_on_this_disk,
        :total_number_of_central_directory_records,
        :size_of_central_directory_in_bytes,
        :offset_to_start_of_central_directory_relative_to_start_of_archive,
        :comment_length,
        :comment
      )
        alias_method :offset, :offset_to_start_of_central_directory_relative_to_start_of_archive
        alias_method :size, :number_of_central_directory_records_on_this_disk

        def self.parse(buffer)
          new(*buffer.unpack("VvvvvVVva*")).freeze
        end
      end

      class CentralDirectoryFileHeader < Struct.new(
        :central_directory_file_header_signature,
        :version_made_by,
        :filesystem_type,
        :version_needed_to_extract,
        :general_purpose_bit_flag,
        :compression_method,
        :file_last_modification_time,
        :file_last_modification_date,
        :crc_32_of_uncompressed_data,
        :compressed_size,
        :uncompressed_size,
        :file_name_length,
        :extra_field_length,
        :file_comment_length,
        :disk_number_where_file_starts,
        :internal_file_attributes,
        :external_file_attributes,
        :relative_offset_of_local_file_header,
        :file_name,
        :extra_field,
        :file_comment,
      )
        alias_method :offset, :relative_offset_of_local_file_header

        def self.parse(buffer)
          new(*buffer.unpack("VCCvvvvvVVVvvvvvVV"))
        end

        def file?
          if filesystem_type != 3 # Unix
            raise "Unknown filesystem_type #{filesystem_type.inspect} for entry #{file_name.inspect}"
          end

          # 4 means directory, 10 means symlink
          external_file_attributes >> 28 == 8
        end
      end

      class LocalFileHeader < Struct.new(
        :local_file_header_signature,
        :version_needed_to_extract,
        :general_purpose_bit_flag,
        :compression_method,
        :file_last_modification_time,
        :file_last_modification_date,
        :crc_32_of_uncompressed_data,
        :compressed_size,
        :uncompressed_size,
        :file_name_length,
        :extra_field_length,
        :file_name,
        :extra_field,
      )
        def self.parse(buffer)
          new(*buffer.unpack("VvvvvvVVVvv"))
        end

        def decompress(io)
          case compression_method
          when 0
            IOSlice.new(io, io.pos, compressed_size)
          when 8
            Inflater.new(IOSlice.new(io, io.pos, compressed_size))
          else
            raise "Unsupported compression_method #{compression_method.inspect} for entry #{file_name.inspect}"
          end
        end
      end
    end
  end

  class ZipTest < Test
    require "base64"

    def test_extracts_files
      # This is a zip file containing one file, path/to/file.txt, with the contents "Hello!\n".
      encoded = <<~END.gsub("\n", "")
        UEsDBAoAAAAAAAZ2xVAAAAAAAAAAAAAAAAAFABwAcGF0aC9VVAkAA2uT2l54
        k9pedXgLAAEE9QEAAAQUAAAAUEsDBAoAAAAAAAl2xVAAAAAAAAAAAAAAAAAI
        ABwAcGF0aC90by9VVAkAA3GT2l56k9pedXgLAAEE9QEAAAQUAAAAUEsDBAoA
        AAAAAE92xVCe2EKwBwAAAAcAAAAQABwAcGF0aC90by9maWxlLnR4dFVUCQAD
        9ZPaXveT2l51eAsAAQT1AQAABBQAAABIZWxsbyEKUEsBAh4DCgAAAAAABnbF
        UAAAAAAAAAAAAAAAAAUAGAAAAAAAAAAQAO1BAAAAAHBhdGgvVVQFAANrk9pe
        dXgLAAEE9QEAAAQUAAAAUEsBAh4DCgAAAAAACXbFUAAAAAAAAAAAAAAAAAgA
        GAAAAAAAAAAQAO1BPwAAAHBhdGgvdG8vVVQFAANxk9pedXgLAAEE9QEAAAQU
        AAAAUEsBAh4DCgAAAAAAT3bFUJ7YQrAHAAAABwAAABAAGAAAAAAAAQAAAKSB
        gQAAAHBhdGgvdG8vZmlsZS50eHRVVAUAA/WT2l51eAsAAQT1AQAABBQAAABQ
        SwUGAAAAAAMAAwDvAAAA0gAAAAAA
      END

      decoded = Base64.decode64(encoded)

      entries = {}
      zip = Zip.new(PathCleaner.new(strip_components: 0))
      zip.call(nil, StringIO.new(decoded)) { |path, io| entries[path] = io.read }
      assert_equal ["path/to/file.txt"], entries.keys
      assert_equal "Hello!\n", entries["path/to/file.txt"]
    end
  end

  class Inflater
    def initialize(src)
      @src = src
      @inflate = Zlib::Inflate.new(-Zlib::MAX_WBITS)
      @buffer = ""
    end

    # TODO this implementation is a bit convoluted, lifted verbatim from rubyzip.
    def read(length = nil, outbuf = "")
      return (length.nil? || length.zero? ? "" : nil) if eof?

      while length.nil? || (@buffer.bytesize < length)
        break if input_finished?
        @buffer << produce_input
      end

      outbuf.replace(@buffer.slice!(0...(length || @buffer.bytesize)))
    end

    private

    def eof?
      @buffer.empty? && input_finished?
    end

    def produce_input
      retried = 0
      begin
        @inflate.inflate(@src.read(32_768))
      rescue Zlib::BufError
        raise if retried >= 5
        retried += 1
        retry
      end
    end

    def input_finished?
      @inflate.finished?
    end
  end

  class InflaterTest < Test
    def setup
      deflate = Zlib::Deflate.new(Zlib::DEFAULT_COMPRESSION, -Zlib::MAX_WBITS)
      @io = Inflater.new(StringIO.new(deflate.deflate("Hello, world!", Zlib::FINISH)))
    end

    def test_read
      assert_equal "Hello, world!", @io.read
    end

    def test_read_length
      assert_equal "Hello", @io.read(5)
      assert_equal ", wor", @io.read(5)
      assert_equal "ld!", @io.read(5)
    end

    def test_eof_read_nil
      @io.read
      assert_equal "", @io.read
    end

    def test_eof_read_zero
      @io.read
      assert_equal "", @io.read(0)
    end

    def test_eof_read_length
      @io.read
      assert_nil @io.read(2)
    end

    def test_io_copy_stream
      dest = StringIO.new
      IO.copy_stream(@io, dest)
      assert_equal "Hello, world!", dest.string
    end
  end

  class IOSlice
    def initialize(source, start, length)
      @source = source
      @source.seek(start)
      @length = length
    end

    def read(length = nil, outbuf = "")
      buffer = nil

      if length == 0
        buffer = ""
      elsif length.nil?
        buffer = @source.read(@length)
        @length = 0
      elsif (length = [@length, length].min) > 0
        buffer = @source.read(length)
        @length -= length
      end

      if buffer
        outbuf.replace(buffer)
      end
    end
  end

  class IOSliceTest < Test
    def setup
      @io = IOSlice.new(StringIO.new("Hello, world!"), 7, 5)
    end

    def test_read
      assert_equal "world", @io.read
    end

    def test_read_length
      assert_equal "wo", @io.read(2)
      assert_equal "rl", @io.read(2)
      assert_equal "d", @io.read(2)
    end

    def test_eof_read_nil
      @io.read
      assert_equal "", @io.read
    end

    def test_eof_read_zero
      @io.read
      assert_equal "", @io.read(0)
    end

    def test_eof_read_length
      @io.read
      assert_nil @io.read(2)
    end

    def test_learning_stringio_eof_read_length_outbuf
      outbuf = "foo"
      io = StringIO.new("")
      io.read(2, outbuf)
      assert_equal "", outbuf
    end

    def test_io_copy_stream
      dest = StringIO.new
      IO.copy_stream(@io, dest)
      assert_equal "world", dest.string
    end
  end

  class PathCleaner
    def self.parse(strip_components)
      new(strip_components: strip_components)
    end

    def initialize(strip_components:)
      @strip_components = strip_components
    end

    def call(name, io, &collector)
      path = Pathname.new(name).cleanpath.to_path
      components = path.split("/")
      components.shift(@strip_components)
      result = components.join("/")
      return if result.empty?
      collector.call(result, io)
    end

    def to_s
      "PathCleaner(strip_components: #{@strip_components})"
    end
  end

  class PathCleanerTest < Test
    def test_cleans_paths
      result = nil
      PathCleaner.new(strip_components: 0).
        call("./path/to/file.txt", nil) { |name| result = name }
      assert_equal "path/to/file.txt", result
    end

    def test_strips_components
      result = nil
      PathCleaner.new(strip_components: 2).
        call("./path/to/my/file.txt", nil) { |name| result = name }
      assert_equal "my/file.txt", result
    end

    def test_skips_stripped_components
      result = nil
      PathCleaner.new(strip_components: 2).
        call("./bar.txt", nil) { |name| result = name }
      assert_nil result
    end
  end

  class MavenCoordinates
    def self.parse(string)
      string.match %r{^([^:]+):([^:]+):([^:]+)$} do |match|
        new(match[1], match[2], match[3])
      end
    end

    def initialize(group, artifact, version, classifier: nil, packaging: :jar)
      @group = group
      @artifact = artifact
      @version = version
      @classifier = classifier
      @packaging = packaging
    end

    def filename(suffix: nil)
      [[@artifact, @version, @classifier].compact.join("-"), @packaging, suffix].compact.join(".")
    end

    def package_path
      "#{@group.gsub(".", "_")}/#{@artifact.gsub("-", "_")}"
    end

    def sources
      self.class.new(@group, @artifact, @version, classifier: :sources, packaging: @packaging)
    end

    def url(repository, suffix: nil)
      repository + [repository.path, *@group.split("."), @artifact, @version, filename(suffix: suffix)].join("/")
    end
  end

  class MavenCoordinatesTest < Test
    def setup
      @subject = MavenCoordinates.parse("a.b.c:x-y-z:1.2.3")
    end

    def test_filename
      assert_equal "x-y-z-1.2.3.jar", @subject.filename
    end

    def test_filename_with_suffix
      assert_equal "x-y-z-1.2.3.jar.md5", @subject.filename(suffix: :md5)
    end

    def test_package_path
      assert_equal "a_b_c/x_y_z", @subject.package_path
    end

    def test_sources_filename
      assert_equal "x-y-z-1.2.3-sources.jar", @subject.sources.filename
    end

    def test_url
      assert_equal URI.parse("https://example.com/maven/a/b/c/x-y-z/1.2.3/x-y-z-1.2.3.jar"),
        @subject.url(URI.parse("https://example.com/maven"))
    end
  end

  class Plan
    def initialize(roots, &children)
      @blocked = {}
      @blocking = {}
      @available = Queue.new
      @mutex = Mutex.new

      traverse = lambda do |node, parent = nil|
        if !@blocked.key?(node)
          @blocked[node] = 0
          @blocking[node] = []
          children[node].each { |child| traverse[child, node] }
        end

        if parent
          @blocked[parent] += 1
          @blocking[node] << parent
        end
      end

      roots.each(&traverse)

      @blocked.each { |node, count| @available << node if count.zero? }
      @blocked.delete_if { |node, count| count.zero? }
    end

    def each(&block)
      if !@available.empty?
        while node = @available.pop
          block.call(node)
          cleanup(node)
        end
      end
    end

    private

    def cleanup(node)
      @mutex.synchronize do
        @blocking[node].each do |parent|
          @blocked[parent] -= 1
          if @blocked[parent] == 0
            @blocked.delete(parent)
            @available << parent
          end
        end

        if @blocked.empty?
          @available.close
        end
      end
    end
  end

  class PlanTest < Test
    def test_each_dependency_ordering
      #   a     b
      #  / \    |
      # c   d   e
      #    / \ / \
      #   f   g   h
      #      / \
      #     i   j
      edges = {
        a: [:c, :d],
        b: [:e],
        c: [],
        d: [:f, :g],
        e: [:g, :h],
        f: [],
        g: [:i, :j],
        h: [],
        i: [],
        j: [],
      }
      record = []
      plan = Plan.new([:a, :b]) { |node| edges[node] }
      plan.each { |node| record << node }
      assert_equal [:c, :f, :i, :j, :h, :g, :d, :e, :a, :b], record
    end

    def test_each_nothing
      record = []
      plan = Plan.new([]) { |node| [] }
      plan.each { |node| record << node }
      assert_equal [], record
    end

    def test_each_no_dependencies
      record = []
      plan = Plan.new([:a, :b]) { |node| [] }
      plan.each { |node| record << node }
      assert_equal [:a, :b], record
    end

    def skip_test_each_parallel_processing
      skip "Seems like these can be flaky."
      record = Queue.new
      plan = Plan.new([:a, :b, :c, :d, :e, :f, :g, :h, :i, :j, :k]) { |node| [] }
      threads = Array.new(3) { |i| Thread.new { plan.each { |node| record << [node, i]; Thread.pass } } }
      threads.each(&:join)
      record_array = []
      record_array << record.pop until record.empty?
      assert_equal [:a, :b, :c, :d, :e, :f, :g, :h, :i, :j, :k], record_array.map(&:first)
      assert_equal [0, 1, 2], record_array.map(&:last).sort.uniq, "Every thread should be part of the processing"
    end

    def test_each_parallel_processing_with_dependency_ordering
      edges = {
        a: [:c, :d],
        b: [:e],
        c: [],
        d: [:f, :g],
        e: [:g, :h],
        f: [],
        g: [:i, :j],
        h: [],
        i: [],
        j: [],
      }
      record = Queue.new
      plan = Plan.new([:a, :b]) { |node| edges[node] }
      threads = Array.new(3) { Thread.new { plan.each { |node| record << node; Thread.pass } } }
      threads.each(&:join)
      assert_equal 10, record.length
    end

    def test_each_avoiding_deadlock
      edges = {
        a: [:c, :d],
        b: [:e],
        c: [],
        d: [:f, :g],
        e: [:g, :h],
        f: [],
        g: [:i, :j],
        h: [],
        i: [],
        j: [],
      }
      record = Queue.new
      plan = Plan.new([:a, :b]) { |node| edges[node] }
      threads = Array.new(3) { Thread.new { plan.each { |node| record << node; Thread.pass } } }
      threads.each(&:join)
    end
  end

  # https://stackoverflow.com/questions/4922867/what-is-the-junit-xml-format-specification-that-hudson-supports/9691131#9691131
  class TestCase
    class Error < Struct.new(:type, :message, :backtrace)
      def self.json_create(object)
        new(
          object.fetch("type"),
          object.fetch("message"),
          object.fetch("backtrace")
        )
      end
    end

    class Failure < Struct.new(:message, :location)
      def self.json_create(object)
        new(
          object.fetch("message"),
          object.fetch("location")
        )
      end
    end

    class Skipped < Struct.new(:message)
      def self.json_create(object)
        new(object.fetch("message"))
      end
    end

    def self.json_create(object)
      new(
        class_name: object.fetch("class_name"),
        name: object.fetch("name"),
        time: object.fetch("time"),
        skipped: object.fetch("skipped", []).map(&Skipped.method(:json_create)),
        errors: object.fetch("errors", []).map(&Error.method(:json_create)),
        failures: object.fetch("failures", []).map(&Failure.method(:json_create)),
        system_out: object.fetch("system_out"),
        system_err: object.fetch("system_err"),
      )
    end

    include Comparable

    attr_reader :ansi_color_code
    attr_reader :result_code
    attr_reader :result_label

    def initialize(**kwargs)
      @class_name = kwargs.fetch(:class_name)
      @name = kwargs.fetch(:name)
      @time = kwargs.fetch(:time)
      @skipped = kwargs.fetch(:skipped)
      @errors = kwargs.fetch(:errors)
      @failures = kwargs.fetch(:failures)
      @system_out = kwargs.fetch(:system_out)
      @system_err = kwargs.fetch(:system_err)
      @result_code = " " # Use a space with reversed video to get a big, colorful bar!

      location = "#{@class_name}##{@name}"

      if @skipped.any?
        @rank = 1
        @result_label = "Skipped"
        @ansi_color_code = "95" # solarized purple is bright magenta, 95
        @to_s = "#{location}:\n#{@skipped.first.message}"
      elsif @failures.any?
        @rank = 2
        @result_label = "Failed"
        @ansi_color_code = "31"
        @to_s = <<~END.chomp
          #{location}:
          #{@failures.first.message}
              #{@failures.first.location}
        END
      elsif @errors.any?
        @rank = 3
        @result_label = "Error"
        @ansi_color_code = "33"
        @to_s = <<~END.chomp
          #{location}:
          #{@errors.first.type}: #{@errors.first.message}
              #{@errors.first.backtrace.join("\n    ")}
        END
      else
        @rank = 0
        @result_label = "Passed"
        @ansi_color_code = "32"
        @to_s = location
      end
    end

    def passed?
      @skipped.empty? && !broken?
    end

    def broken?
      @errors.any? || @failures.any?
    end

    def to_s
      @to_s
    end

    def <=>(other)
      sort_key <=> other.sort_key
    end

    def sort_key
      [@rank, @class_name, @name]
    end
  end

  class LintTest < Test
    def test_all_tests_are_tests
      assert_equal [], Wake.constants.
                     select { |name| name =~ /^.+Test$/ }.
                     map { |name| Wake.const_get(name) }.
                     select { |klass| !klass.ancestors.include?(Test) }
    end
  end

  class MinitestReporter
    def initialize(console)
      @console = console
      @ok = true
    end

    def start
    end

    def record(result)
      @console.report_test_result(test_case(result))
      @ok &&= (result.passed? || result.skipped?)
    end

    def report
    end

    def passed?
      @ok
    end

    private

    def test_case(result)
      TestCase.new(
        class_name: result.class.name,
        name: result.name,
        time: result.time,
        skipped: result.failures.
          select { |f| Minitest::Skip === f }.
          collect { |f| TestCase::Skipped.new(f.message) },
        errors: result.failures.
          select { |f| Minitest::UnexpectedError === f }.
          collect { |f| TestCase::Error.new(f.error.class.name, f.error.message, Minitest.filter_backtrace(f.backtrace)) },
        failures: result.failures.
          select { |f| Minitest::Assertion === f }.
          collect { |f| TestCase::Failure.new(f.error.message, Minitest.filter_backtrace(f.error.backtrace).first) },
        system_out: "",
        system_err: "",
      )
    end
  end

  class FileGroupInfo < Struct.new(:paths)
    def only
      raise "More than one file! #{paths.inspect}" unless paths.length == 1
      paths[0]
    end
  end

  class FileInfo < Struct.new(:path)
    # TODO any behavior?
  end

  class JavaArchiverInfo < Struct.new(:jar, :libs, keyword_init: true)
    def files
      [jar, *libs]
    end

    def arguments
      # So, it seems like, when we have multiple jvms running, there's some leakage of knowledge about where ${JAVA_HOME}/lib is.
      [
        "-J-Djava.home=%{pwd}/#{java_home}",
        "-J-Djava.library.path=%{pwd}/#{java_home}/lib",
        "-J-Dsun.boot.library.path=%{pwd}/#{java_home}/lib",
      ]
    end

    private

    def java_home
      jar.chomp("/bin/jar")
    end
  end

  class JavaCompilerInfo < Struct.new(:javac, :libs, keyword_init: true)
    def files
      [javac, *libs]
    end

    def compile(srcs:, deps:, context:)
      source_paths = srcs.map { |path| context.expand_path(path) }
      dependency_paths = deps.map { |dep| dep.fetch(JavaInfo).jar }
      output = context.expand_path("lib%{name}.jar")

      context.run(inputs: [javac, jar, *libs, *source_paths, *dependency_paths], parameters: [], outputs: [output]) do |fs|
        fs.mktmpdir do |tmp|
          fs.exec!(javac, "-d", tmp, "-cp", *dependency_paths.join(":"), *source_paths) # TODO source version, target version?
          fs.exec!(jar, "cf", output, "-C", tmp, ".")
        end
      end

      [JavaInfo.new(
        jar: output,
        deps: deps.map { |dep| dep.fetch(JavaInfo) },
        neverlink: false,
      )]
    end
  end

  class JavaInfo < Struct.new(:jar, :deps, :neverlink, keyword_init: true)
    def transitive_runtime_dependencies
      neverlink ? [] : [jar, *deps.map { |dep| dep.transitive_runtime_dependencies }]
    end
  end

  class JavaRuntimeInfo < Struct.new(:java, :libs, keyword_init: true)
    def files
      [java, *libs]
    end

    def arguments
      # So, it seems like, when we have multiple jvms running, there's some leakage of knowledge about where ${JAVA_HOME}/lib is.
      [
        "-Djava.home=%{pwd}/#{java_home}",
        "-Djava.library.path=%{pwd}/#{java_home}/lib",
        "-Dsun.boot.library.path=%{pwd}/#{java_home}/lib",
      ]
    end

    private

    def java_home
      java.chomp("/bin/java")
    end
  end

  class NodeRuntimeInfo < Struct.new(:node, keyword_init: true)
  end

  # https://kotlinlang.org/docs/reference/compiler-reference.html
  class KotlinJsCompilerInfo < Struct.new(:java_archiver, :java_runtime, :preloader, :compiler, :stdlib, :stdlib_js, :runtime, keyword_init: true)
    def compile(srcs:, deps:, plugins:, context:)
      source_paths = srcs.map { |path| context.expand_path(path) }
      dependencies = deps.map { |dep| dep.fetch(KotlinJsInfo) }
      dependency_paths = dependencies.map(&:jar)
      plugin_paths = plugins.map { |plugin| plugin.fetch(JavaInfo).jar }

      output_filename = context.expand_path("%{name}").
        gsub("src/main/kotlin/", "").
        gsub("src/test/kotlin/", "").
        gsub("/", "-")

      output_js = context.expand_path("#{output_filename}.js")
      output_jar = context.expand_path("#{output_filename}.jar")

      parameters = [
        "-api-version", "1.4",
        "-language-version", "1.4",
        "-meta-info",
        "-module-kind", "umd",
        "-target", "v6",
        "-Werror",
        "-Xopt-in=kotlin.RequiresOptIn",
        *plugin_paths.map { |path| "-Xplugin=#{path}" },
      ]

      context.run(inputs: [*java_archiver.files, *java_runtime.files, preloader, compiler, *plugin_paths, stdlib.jar, stdlib_js.jar, *runtime, *source_paths, *dependency_paths], parameters: [*java_archiver.arguments, *java_runtime.arguments, *parameters, File.basename(output_js)], outputs: [output_jar, output_js]) do |fs|
        fs.mktmpdir do |tmp|
          fs.exec!(
            java_runtime.java,
            java_runtime.arguments,
            "-cp", preloader,
            "org.jetbrains.kotlin.preloading.Preloader",
            "-cp", compiler,
            "org.jetbrains.kotlin.cli.js.K2JSCompiler",
            "-libraries", dependency_paths.join(":"),
            "-output", File.join(tmp, File.basename(output_js)),
            parameters,
            source_paths
          )

          fs.exec!(
            java_archiver.jar,
            java_archiver.arguments,
            "cf",
            output_jar,
            "-C",
            tmp,
            "."
          )

          fs.exec!("cp", File.join(tmp, File.basename(output_js)), output_js)
        end
      end

      [KotlinJsInfo.new(
        jar: output_jar,
        js: output_js,
        deps: [stdlib_js, *dependencies],
      )]
    end
  end

  class KotlinJvmCompilerInfo < Struct.new(:java_runtime, :preloader, :compiler, :stdlib, :runtime, keyword_init: true)
    # To debug: ./var/tmp/lib/java/jdk14_macos/bin/jdb -attach localhost:9253
    def compile(srcs:, deps:, plugins:, debug: false, context:)
      source_paths = srcs.map { |path| context.expand_path(path) }
      dependencies = deps.map { |dep| dep.fetch(JavaInfo) }.append(stdlib)
      dependency_paths = dependencies.map { |java_info| java_info.jar }
      plugin_paths = plugins.map { |plugin| plugin.fetch(JavaInfo).jar }
      output = context.expand_path("lib%{name}.jar")
      java_parameters = []
      java_parameters << "-agentlib:jdwp=transport=dt_socket,server=y,address=9253" if debug
      kotlinc_parameters = [
        "-api-version", "1.4",
        "-language-version", "1.4",
        "-jvm-target", "14",
        "-Werror",
        "-Xopt-in=kotlin.RequiresOptIn",
        "-Xuse-ir",
        *plugin_paths.map { |path| "-Xplugin=#{path}" },
      ]

      context.run(
        inputs: [*java_runtime.files, preloader, compiler, *plugin_paths, *runtime, *source_paths, *dependency_paths],
        parameters: [*java_runtime.arguments, *java_parameters, *kotlinc_parameters],
        outputs: [output],
      ) do |fs|
        fs.exec!(
          java_runtime.java,
          java_runtime.arguments,
          java_parameters,
          "-cp", preloader,
          "org.jetbrains.kotlin.preloading.Preloader",
          "-cp", compiler,
          "org.jetbrains.kotlin.cli.jvm.K2JVMCompiler",
          "-cp", dependency_paths.join(":"),
          "-d", output,
          kotlinc_parameters,
          source_paths,
        )
      end

      [JavaInfo.new(
        jar: output,
        deps: dependencies,
        neverlink: false,
      )]
    end
  end

  class KotlinNativeCompilerInfo < Struct.new(:java_runtime, keyword_init: true)
  end

  class KotlinJsInfo < Struct.new(:jar, :js, :deps, keyword_init: true)
    def transitive_runtime_dependencies
      [js, *deps.map(&:transitive_runtime_dependencies)]
    end

    def require_path
      File.basename(js).chomp(".js")
    end
  end

  class TestExecutableInfo < Struct.new(:executable, :runfiles, :arguments, :env, keyword_init: true)
    # TODO move any relevant behavior here
  end

  if Kernel.const_defined?(:Minitest)
    Minitest.extensions << :wake
    def Minitest.plugin_wake_init(options)
      $stdout = console = Console.new(options[:io])
      reporter.reporters = [MinitestReporter.new(console)]
      at_exit { console.join }
    end
  elsif __FILE__ == $0
    STDOUT.sync = true
    exit Wake.run(*ARGV)
  end
end
