#!/usr/bin/env ruby -wU --disable-all

require "digest/sha2"
require "fileutils"
require "find"
require "io/console"
require "net/http"
require "open3"
require "pathname"
require "rbconfig"
require "rubygems" # TODO write a simple version of Gem::Package::TarReader?
require "rubygems/package"
require "set"
require "shellwords"
require "stringio"
require "tempfile"
require "tmpdir"
require "uri"
require "zlib"

module Wake
  class FileGroupInfo < Struct.new(:paths)
    def only
      raise "More than one file! #{paths.inspect}" unless paths.length == 1
      paths[0]
    end
  end

  class FileInfo < Struct.new(:path)
    # TODO any behavior?
  end

  class JavaCompilerInfo < Struct.new(:javac, :jar, :libs, keyword_init: true)
    def files
      [javac, jar, *libs]
    end

    def compile(srcs:, deps:, context:)
      source_paths = srcs.map { |path| context.expand_path(path) }
      dependency_paths = deps.map { |dep| dep.fetch(JavaInfo).jar }
      output = context.expand_path("lib%{name}.jar")

      context.run(inputs: [javac, jar, *libs, *source_paths, *dependency_paths], parameters: [], outputs: [output]) do |fs|
        fs.mktmpdir do |tmp|
          fs.exec!(javac, "-d", tmp, "-cp", *dependency_paths.join(":"), *source_paths) # TODO source version, target version?
          fs.exec!(jar, "cf", output, "-C", tmp, ".")
        end
      end

      [JavaInfo.new(
        jar: output,
        deps: deps.map { |dep| dep.fetch(JavaInfo) },
        neverlink: false,
      )]
    end
  end

  class JavaInfo < Struct.new(:jar, :deps, :neverlink, keyword_init: true)
    def transitive_runtime_dependencies
      neverlink ? [] : [jar, *deps.map { |dep| dep.transitive_runtime_dependencies }]
    end
  end

  class JavaRuntimeInfo < Struct.new(:java, :libs, keyword_init: true)
    def files
      [java, *libs]
    end
  end

  class NodeRuntimeInfo < Struct.new(:node, keyword_init: true)
  end

  # https://kotlinlang.org/docs/reference/compiler-reference.html
  class KotlinCompilerInfo < Struct.new(:java_compiler, :java_runtime, :preloader, :compiler, :stdlib, :stdlib_js, :runtime, keyword_init: true)
    def compile_js(srcs:, deps:, context:)
      source_paths = srcs.map { |path| context.expand_path(path) }
      dependencies = deps.map { |dep| dep.fetch(KotlinJsInfo) }
      dependency_paths = dependencies.map(&:jar)
      output_js = context.expand_path("lib%{name}.js")
      output_jar = context.expand_path("lib%{name}.jar")
      parameters = [
        "-meta-info",
        "-module-kind", "umd",
        "-target", "v6",
        "-Werror",
      ]

      # Make the js file.
      context.run(inputs: [*java_compiler.files, *java_runtime.files, preloader, compiler, stdlib.jar, stdlib_js.jar, *runtime, *source_paths, *dependency_paths], parameters: parameters, outputs: [output_js]) do |fs|
        fs.exec!(
          java_runtime.java,
          "-cp", preloader,
          "org.jetbrains.kotlin.preloading.Preloader",
          "-cp", compiler,
          "org.jetbrains.kotlin.cli.js.K2JSCompiler",
          "-libraries", dependency_paths.join(":"),
          "-output", output_js,
          parameters,
          source_paths
        )
      end

      # Make the library.
      context.run(inputs: [*java_compiler.files, *java_runtime.files, preloader, compiler, stdlib.jar, stdlib_js.jar, *runtime, *source_paths, *dependency_paths], parameters: parameters, outputs: [output_jar]) do |fs|
        fs.mktmpdir do |tmp|
          fs.exec!(
            java_runtime.java,
            "-cp", preloader,
            "org.jetbrains.kotlin.preloading.Preloader",
            "-cp", compiler,
            "org.jetbrains.kotlin.cli.js.K2JSCompiler",
            "-libraries", dependency_paths.join(":"),
            "-output", File.join(tmp, output_js),
            parameters,
            source_paths
          )

          fs.exec!(java_compiler.jar, "cf", output_jar, "-C", tmp, ".")
        end
      end

      [KotlinJsInfo.new(
        jar: output_jar,
        js: output_js,
        deps: [stdlib_js, *dependencies],
      )]
    end

    def compile_jvm(srcs:, deps:, context:)
      source_paths = srcs.map { |path| context.expand_path(path) }
      dependencies = deps.map { |dep| dep.fetch(JavaInfo) }.append(stdlib)
      dependency_paths = dependencies.map { |java_info| java_info.jar }
      output = context.expand_path("lib%{name}.jar")
      parameters = [
        "-jvm-target", "12",
        "-Werror",
      ]

      context.run(inputs: [*java_runtime.files, preloader, compiler, *runtime, *source_paths, *dependency_paths], parameters: parameters, outputs: [output]) do |fs|
        fs.exec!(
          java_runtime.java,
          "-cp", preloader,
          "org.jetbrains.kotlin.preloading.Preloader",
          "-cp", compiler,
          "org.jetbrains.kotlin.cli.jvm.K2JVMCompiler",
          "-cp", dependency_paths.join(":"),
          "-d", output,
          parameters,
          source_paths
        )
      end

      [JavaInfo.new(
        jar: output,
        deps: dependencies,
        neverlink: false,
      )]
    end
  end

  class KotlinJsInfo < Struct.new(:jar, :js, :deps, keyword_init: true)
    def transitive_runtime_dependencies
      [js, *deps.map(&:transitive_runtime_dependencies)]
    end
  end

  class TestExecutableInfo < Struct.new(:executable, :runfiles, :arguments, :env, keyword_init: true)
    # TODO move any relevant behavior here
  end

  def self.run
    console = Console.new(STDOUT)

    registry = Registry.new

    registry.new_target(
      label: Label.parse("//tools:console"),
      # Dummy for now because ruby 2.5.3 on Travis otherwise complains splatting no kwargs.
      rule: lambda { |context, dummy:| [console] },
      attributes: AttributeSchema.new({ dummy: Attribute.new(String) }).parse({ dummy: "42" }),
    )

    registry.new_target(
      label: Label.parse("//tools:http"),
      rule: lambda { |context, console:| [HttpDownloader.new(console.fetch(Console))] },
      attributes: AttributeSchema.new({
        console: Attribute.new(Label, default: "//tools:console", providers: [Console]),
      }).parse({}),
    )

    registry.new_rule(
      :http_file,
      attributes: {
        http: Attribute.new(Label, default: "//tools:http", providers: [HttpDownloader]),
        url: Attribute.new(URI),
        sha256: Attribute.new(Verifier),
      },
      implementation: ->(context, http:, url:, sha256:) {
        path = context.expand_path(url.path.split("/").last)
        # TODO work back in (a new kind of?) verifier
        context.run(parameters: [url], outputs: [path]) do |fs|
          fs.open(path, "wb") do |io|
            http.fetch(HttpDownloader).get(url, io)
          end
        end
        [FileInfo.new(path)]
      },
    )

    registry.new_rule(
      :extract,
      attributes: {
        archive: Attribute.new(Label, providers: [FileInfo]),
        format: Attribute.new(Extractor),
        paths: Attribute.new(String, list: true),
        permissions: Attribute.new(Integer, default: 0644),
        strip_components: Attribute.new(PathCleaner, default: 0),
      },
      implementation: ->(context, archive:, format:, paths:, permissions:, strip_components:) {
        context.run(inputs: [archive.fetch(FileInfo).path], parameters: [format, paths, permissions, strip_components], outputs: paths.map { |path| context.expand_path(path) }) do |fs|
          fs.open(archive.fetch(FileInfo).path, "rb") do |archive_io|
            format.extract(archive_io, strip_components: strip_components) do |entry_path, entry_io|
              if paths.include?(entry_path)
                fs.open(context.expand_path(entry_path), "wb", permissions: permissions) do |output_io|
                  IO.copy_stream(entry_io, output_io)
                end
              end
            end
          end
        end

        file_group_info = FileGroupInfo.new(paths.map { |path| context.expand_path(path) })
        result = [file_group_info]
        result << FileInfo.new(file_group_info.only) if paths.length == 1
        result
      },
    )

    registry.new_rule(
      :java_compiler,
      attributes: {
        javac: Attribute.new(Label, providers: [FileInfo]),
        jar: Attribute.new(Label, providers: [FileInfo]),
        libs: Attribute.new(Label, providers: [FileGroupInfo]),
      },
      implementation: ->(context, javac:, jar:, libs:) {
        [JavaCompilerInfo.new(
          javac: javac.fetch(FileInfo).path,
          jar: jar.fetch(FileInfo).path,
          libs: libs.fetch(FileGroupInfo).paths,
        )]
      },
    )

    registry.new_rule(
      :java_import,
      attributes: {
        jar: Attribute.new(Label, providers: [FileInfo]),
        neverlink: Attribute.new(TrueClass, default: false),
      },
      implementation: ->(context, jar:, neverlink:) {
        [JavaInfo.new(
          jar: jar.fetch(FileInfo).path,
          deps: [],
          neverlink: neverlink,
        )]
      },
    )

    registry.new_rule(
      :java_lib,
      attributes: {
        compiler: Attribute.new(Label, default: "//lib/java:compiler", providers: [JavaCompilerInfo]),
        srcs: Attribute.new(String, list: true),
        deps: Attribute.new(Label, list: true, providers: [JavaInfo]),
      },
      implementation: ->(context, deps:, compiler:, srcs:) {
        jdk = compiler.fetch(JavaCompilerInfo)
        jdk.compile(srcs: srcs, deps: deps, context: context)
      },
    )

    registry.new_rule(
      :java_runtime,
      attributes: {
        java: Attribute.new(Label, providers: [FileInfo]),
        libs: Attribute.new(Label, providers: [FileGroupInfo]),
      },
      implementation: ->(context, java:, libs:) {
        [JavaRuntimeInfo.new(
          java: java.fetch(FileInfo).path,
          libs: libs.fetch(FileGroupInfo).paths,
        )]
      },
    )

    registry.new_rule(
      :kotlin_compiler,
      attributes: {
        java_compiler: Attribute.new(Label, default: "//lib/java:compiler", providers: [JavaCompilerInfo]),
        java_runtime: Attribute.new(Label, default: "//lib/java:runtime", providers: [JavaRuntimeInfo]),
        preloader: Attribute.new(Label, providers: [FileInfo]),
        compiler: Attribute.new(Label, providers: [FileInfo]),
        stdlib: Attribute.new(Label, providers: [JavaInfo]),
        stdlib_js: Attribute.new(Label, providers: [KotlinJsInfo]),
        runtime: Attribute.new(Label, providers: [FileGroupInfo]),
      },
      implementation: ->(context, java_compiler:, java_runtime:, preloader:, compiler:, stdlib:, stdlib_js:, runtime:) {
        [KotlinCompilerInfo.new(
          java_compiler: java_compiler.fetch(JavaCompilerInfo),
          java_runtime: java_runtime.fetch(JavaRuntimeInfo),
          preloader: preloader.fetch(FileInfo).path,
          compiler: compiler.fetch(FileInfo).path,
          stdlib: stdlib.fetch(JavaInfo),
          stdlib_js: stdlib_js.fetch(KotlinJsInfo),
          runtime: runtime.fetch(FileGroupInfo).paths,
        )]
      },
    )

    registry.new_rule(
      :kt_js_import,
      attributes: {
        jar: Attribute.new(Label, providers: [FileInfo]),
        js_path: Attribute.new(String),
      },
      implementation: ->(context, jar:, js_path:) {
        format = Extractor.parse(:zip)

        context.run(inputs: [jar.fetch(FileInfo).path], parameters: [format, js_path], outputs: [context.expand_path(js_path)]) do |fs|
          fs.open(jar.fetch(FileInfo).path, "rb") do |archive_io|
            # TODO can we nest strip_components inside the block instead? Would be nice to make it optional.
            # TODO and, while we're at it, couldn't we nest tar inside gzip in the same way? None of this @delegate stuff.
            format.extract(archive_io, strip_components: PathCleaner.parse(0)) do |entry_path, entry_io|
              if js_path == entry_path
                fs.open(context.expand_path(entry_path), "wb") do |output_io|
                  IO.copy_stream(entry_io, output_io)
                end
              end
            end
          end
        end

        [KotlinJsInfo.new(
          jar: jar.fetch(FileInfo).path,
          js: context.expand_path(js_path),
          deps: [],
        )]
      },
    )

    registry.new_rule(
      :kt_js_lib,
      attributes: {
        kotlin_compiler: Attribute.new(Label, default: "//lib/kotlin:compiler", providers: [KotlinCompilerInfo]),
        srcs: Attribute.new(String, list: true),
        deps: Attribute.new(Label, list: true, providers: [KotlinJsInfo]),
      },
      implementation: ->(context, kotlin_compiler:, srcs:, deps:) {
        compiler = kotlin_compiler.fetch(KotlinCompilerInfo)
        compiler.compile_js(srcs: srcs, deps: deps, context: context)
      },
    )

    registry.new_rule(
      :kt_js_test,
      attributes: {
        node_runtime: Attribute.new(Label, default: "//lib/node:runtime", providers: [NodeRuntimeInfo]),
        runtime_deps: Attribute.new(Label, list: true, providers: [KotlinJsInfo]),
        test_module: Attribute.new(String),
        test_runner: Attribute.new(Label, default: "//src/main/kotlin/wake/test:wake-test", providers: [KotlinJsInfo]),
      },
      implementation: ->(context, node_runtime:, runtime_deps:, test_module:, test_runner:) {
        node = node_runtime.fetch(NodeRuntimeInfo)

        modules = [test_runner, *runtime_deps].map { |dep| dep.fetch(KotlinJsInfo).transitive_runtime_dependencies }.flatten.sort.uniq

        script = context.expand_path("%{name}-test-script.js")

        contents = <<~END
          'use strict';
          var kotlin_test = require("kotlin-test");
          var wake_test = require("libwake-test").org.matthewtodd.wake.test;
          kotlin_test.setAdapter(new wake_test.WakeTest());
          require("#{test_module}");
        END

        context.run(inputs: [], parameters: [contents], outputs: [script]) do |fs|
          fs.open(script, "wb") { |io| io.write(contents) }
        end

        [TestExecutableInfo.new(
          executable: node.node,
          runfiles: [script, *modules],
          arguments: [script],
          env: { "NODE_PATH" => modules.map { |path| File.join(".", File.dirname(path)) }.uniq.join(":") },
        )]
      },
    )

    registry.new_rule(
      :kt_jvm_lib,
      attributes: {
        kotlin_compiler: Attribute.new(Label, default: "//lib/kotlin:compiler", providers: [KotlinCompilerInfo]),
        srcs: Attribute.new(String, list: true),
        deps: Attribute.new(Label, list: true, providers: [JavaInfo]),
      },
      implementation: ->(context, kotlin_compiler:, srcs:, deps:) {
        compiler = kotlin_compiler.fetch(KotlinCompilerInfo)
        compiler.compile_jvm(srcs: srcs, deps: deps, context: context)
      },
    )

    registry.new_rule(
      :kt_jvm_test,
      attributes: {
        java_runtime: Attribute.new(Label, default: "//lib/java:runtime", providers: [JavaRuntimeInfo]),
        runtime_deps: Attribute.new(Label, list: true, providers: [JavaInfo]),
        test_class: Attribute.new(String),
        test_runner: Attribute.new(Label, default: "//src/main/kotlin/wake/test:junit", providers: [JavaInfo]),
      },
      implementation: ->(context, java_runtime:, runtime_deps:, test_class:, test_runner:) {
        jre = java_runtime.fetch(JavaRuntimeInfo)

        classpath = []
        classpath.append(test_runner)
        classpath.concat(runtime_deps)
        classpath = classpath.map { |dep| dep.fetch(JavaInfo).transitive_runtime_dependencies }.flatten.sort.uniq

        [TestExecutableInfo.new(
          executable: jre.java,
          runfiles: jre.files.concat(classpath),
          arguments: [
            "-cp", classpath.join(":"),
            "org.matthewtodd.wake.test.JUnitLauncherKt", # TODO could pull this into something provided by the test_runner jar.
            test_class,
          ],
          env: {},
        )]
      },
    )

    registry.new_rule(
      :node_runtime,
      attributes: {
        node: Attribute.new(Label, providers: [FileInfo]),
      },
      implementation: ->(context, node:) {
        [NodeRuntimeInfo.new(
          node: node.fetch(FileInfo).path,
        )]
      },
    )

    registry.new_macro(
      :maven_jar,
      attributes: {
        repository: Attribute.new(URI, default: "https://repo1.maven.org/maven2"),
        artifact: Attribute.new(MavenCoordinates),
        sha256: Attribute.new(Verifier),
      },
      implementation: ->(context, repository:, artifact:, sha256:) {
        context.package(artifact.package_path) do
          http_file(
            name: artifact.filename,
            url: artifact.url(repository),
            sha256: sha256,
          )

          java_import(
            name: "jar",
            jar: artifact.filename,
          )
        end
      },
    )

    # TODO load in parallel?
    Pathname.glob("**/BUILD") do |build|
      registry.new_package(build.dirname.to_path).instance_eval(build.read, build.to_path)
    end

    targets = registry.resolve(
      platform: Platform.from_ruby_config,
    )

    actions = Actions.new(RealFilesystem.new(Dir.pwd))
    providers = ProviderRegistry.new

    build_plan = Plan.new(targets.keys) { |label| targets.fetch(label).dependencies }

    # TODO analyze in parallel?
    build_plan.each do |label|
      context = Context.new(actions, providers, label)
      target = targets.fetch(label)
      target.invoke(context)
    end

    tests = providers.of(TestExecutableInfo)
    test_plan = Plan.new(tests.keys) { |label| [] } # no dependencies
    test_plan.each do |label|
      test = tests.fetch(label)
      out = File.join(label.package, "#{label.name}-out.txt")

      action_did_run = false

      actions.run(label, inputs: [test.executable, *test.runfiles], parameters: [*test.arguments, *test.env.flatten], outputs: [out]) do |fs|
        action_did_run = true
        rd, wr = IO.pipe
        reader = Thread.new { until rd.eof?; console.report_test_result(label, rd.readline.chomp); end }
        fs.open(out, "wb") do |io|
          fs.exec!(test.executable, *test.arguments, out: CompositeIO.new(io, wr), env: test.env)
        end
        wr.close
        reader.join
      end

      if !action_did_run
        # TODO var/tmp is duplication with Actions
        File.open(File.join("var/tmp", out), "rb") do |io|
          until io.eof?
            console.report_test_result(label, io.readline.chomp)
          end
        end
      end
    end

    actions.expire(before: Time.now - (60 * 60 * 24))

    0
  end

  if Kernel.const_defined? :Minitest
    Test = Minitest::Test
  else
    Test = Object
  end

  class Context
    def initialize(actions, providers, label)
      @actions = actions
      @providers = providers
      @label = label
    end

    def invoke(rule, attributes)
      # TODO do we want rules to register providers more explicitly?
      @providers[@label] = rule.call(self, **attributes.using(@providers)) || []
    end

    def expand_path(path)
      File.join(@label.package, path.gsub("%{name}", @label.name))
    end

    def run(inputs: [], parameters: [], outputs:, &block)
      @actions.run(@label, inputs: inputs, parameters: parameters, outputs: outputs, &block)
    end
  end

  class Actions
    def initialize(fs)
      @fs = fs
    end

    def run(label, inputs: [], parameters: [], outputs:, &block)
      alien = outputs.reject { |path| path.start_with?(label.package) }
      raise "Action for #{label} cannot produce outputs outside of #{label.package}, but claims #{alien}." if alien.any?

      key = Digest::SHA256.hexdigest("#{label}-#{inputs.map { |path| checksum(path) }.join("-")}-#{parameters.join("-")}-#{outputs.join("-")}")

      if !@fs.exists?("var/cache/#{key}")
        @fs.mktmpdir do |dir|
          inputs.each do |path|
            if @fs.exists?(path)
              @fs.link(path, "#{dir}/#{path}")
            else
              @fs.link("var/tmp/#{path}", "#{dir}/#{path}")
            end
          end

          block.call(@fs.sandbox(dir))

          missing = outputs.reject { |path| @fs.exists?("#{dir}/#{path}") }
          raise "Action for #{label} failed to produce outputs #{missing}." if missing.any?

          outputs.each do |path|
            @fs.link("#{dir}/#{path}", "var/cache/#{key}/#{path}")
          end
        end
      end

      outputs.each do |path|
        @fs.link("var/cache/#{key}/#{path}", "var/tmp/#{path}")
      end
    end

    def expire(before:)
      @fs.purge("var/cache", before: before)
    end

    private

    def checksum(path)
      if @fs.exists?(path)
        @fs.checksum(path)
      else
        @fs.checksum("var/tmp/#{path}")
      end
    end
  end

  class ActionsTest < Test
    def setup
      @files = {}
      @actions = Actions.new(InMemoryFilesystem.new("/workspace", @files))
    end

    def test_run_caching
      @files["/workspace/src/foo.txt"] = "FOO"
      @files["/workspace/src/bar.txt"] = "BAR"

      @actions.run(Label["//src:baz"], outputs: ["src/baz.out"]) do |fs|
        fs.open("src/baz.out", "w") { |io| io.puts("BAZ") }
      end

      @actions.run(Label["//src:foo"], inputs: ["src/foo.txt", "src/bar.txt", "src/baz.out"], outputs: ["src/foo.out"]) do |fs|
        fs.open("src/foo.out", "w") do |io|
          2.times { fs.open("src/foo.txt", "r") { |foo| io.puts(foo.read) } }
          2.times { fs.open("src/bar.txt", "r") { |bar| io.puts(bar.read) } }
          2.times { fs.open("src/baz.out", "r") { |baz| io.puts(baz.read) } }
        end
      end

      assert_equal(<<~END, @files.fetch("/workspace/var/tmp/src/foo.out"))
        FOO
        FOO
        BAR
        BAR
        BAZ
        BAZ
      END

      # nothing changes (re-run with raising block?)
      @actions.run(Label["//src:foo"], inputs: ["src/foo.txt", "src/bar.txt", "src/baz.out"], outputs: ["src/foo.out"]) do |fs|
        raise "Shouldn't get here!"
      end

      # source changes
      @files["/workspace/src/foo.txt"] = "FOOFOO"

      @actions.run(Label["//src:foo"], inputs: ["src/foo.txt", "src/bar.txt", "src/baz.out"], outputs: ["src/foo.out"]) do |fs|
        fs.open("src/foo.out", "w") do |io|
          2.times { fs.open("src/foo.txt", "r") { |foo| io.puts(foo.read) } }
          2.times { fs.open("src/bar.txt", "r") { |bar| io.puts(bar.read) } }
          2.times { fs.open("src/baz.out", "r") { |baz| io.puts(baz.read) } }
        end
      end

      assert_equal(<<~END, @files.fetch("/workspace/var/tmp/src/foo.out"))
        FOOFOO
        FOOFOO
        BAR
        BAR
        BAZ
        BAZ
      END

      # generated changes
      @actions.run(Label["//src:baz"], parameters: [:changed], outputs: ["src/baz.out"]) do |fs|
        fs.open("src/baz.out", "w") { |io| io.puts("BAZBAZ") }
      end

      @actions.run(Label["//src:foo"], inputs: ["src/foo.txt", "src/bar.txt", "src/baz.out"], outputs: ["src/foo.out"]) do |fs|
        fs.open("src/foo.out", "w") do |io|
          2.times { fs.open("src/foo.txt", "r") { |foo| io.puts(foo.read) } }
          2.times { fs.open("src/bar.txt", "r") { |bar| io.puts(bar.read) } }
          2.times { fs.open("src/baz.out", "r") { |baz| io.puts(baz.read) } }
        end
      end

      assert_equal(<<~END, @files.fetch("/workspace/var/tmp/src/foo.out"))
        FOOFOO
        FOOFOO
        BAR
        BAR
        BAZBAZ
        BAZBAZ
      END
    end
  end

  class InMemoryFilesystem
    def initialize(base, files)
      @base = base
      @files = files
    end

    def checksum(path)
      # A real filesystem would do some caching here, since these are expensive.
      Digest::SHA256.hexdigest(@files.fetch(absolute_path(path)))
    end

    def exists?(path)
      # First clause is for files.
      # Second clause is a hack for directories, since we're not modeling them fully, just putting path -> contents in a Hash.
      path = absolute_path(path)
      @files.key?(path) || @files.keys.any? { |candidate| candidate.start_with?(path) && candidate[path.length] == "/" }
    end

    def link(src, dest)
      @files[absolute_path(dest)] = @files.fetch(absolute_path(src))
    end

    def mktmpdir(&block)
      tmp = "/tmp/#{Time.now.strftime("%Y%m%d")}-#{$$}-#{rand(0x100000000).to_s(36)}"
      yield tmp
    ensure
      @files.delete_if { |path, content| path.start_with?(tmp) }
    end

    def sandbox(base)
      Sandbox.new(absolute_path(base), @files)
    end

    private

    def absolute_path(path)
      path.start_with?("/") ? path : "#{@base}/#{path}"
    end

    class Sandbox
      def initialize(base, files)
        @base = base
        @files = files
      end

      def open(path, mode, permissions: 0644, &block)
        case mode
        when "r"
          yield StringIO.new(@files.fetch(File.join(@base, path)))
        when "w"
          io = StringIO.new
          yield io
          @files[File.join(@base, path)] = io.string
        else
          raise "Unsupported mode #{mode}"
        end
      end

      def exec!(*args)
        raise "InMemoryFilesystem::Sandbox doesn't support exec!"
      end

      def mktmpdir(&block)
        raise "InMemoryFilesystem::Sandbox doesn't support mktmpdir!"
      end
    end
  end

  class RealFilesystem
    def initialize(base)
      @base = base
      @checksums = {}
      @mtimes = {}
    end

    def checksum(path)
      path = absolute_path(path)

      # TODO if these stats get expensive, maybe we eagerly cache checksums for
      # generated files and take a separate path for "volatile" source files.
      mtime = File.mtime(path)

      if @mtimes.key?(path) && @mtimes[path] == mtime
        @checksums.fetch(path)
      else
        @mtimes[path] = mtime
        @checksums[path] = Digest::SHA256.file(path).hexdigest
      end
    end

    def exists?(path)
      path = absolute_path(path)
      File.exist?(path)
    end

    def link(src, dest)
      src = absolute_path(src)
      dest = absolute_path(dest)
      FileUtils.mkdir_p(File.dirname(dest))
      FileUtils.ln(src, dest, force: true)
    end

    def purge(path, before:)
      path = absolute_path(path)

      Find.find(path).
        map { |p| [p, File.stat(p)] }.
        select { |p, stat| stat.file? }.
        select { |p, stat| stat.mtime < before }.
        select { |p, stat| stat.nlink == 1 }.
        each { |p, stat| FileUtils.remove_entry(p) }

      Find.find(path).
        select { |p| File.directory?(p) }.
        sort.
        reverse_each { |p| FileUtils.remove_entry(p) if Dir.empty?(p) }
    end

    def mktmpdir(&block)
      Dir.mktmpdir(&block)
    end

    def sandbox(base)
      Sandbox.new(absolute_path(base))
    end

    private

    def absolute_path(path)
      path.start_with?("/") ? path : "#{@base}/#{path}"
    end

    class Sandbox
      class ExecutionError < RuntimeError
        attr_reader :status
        attr_reader :out
        attr_reader :err
        attr_reader :env

        def initialize(args:, status:, out:, err:, env:, files: [])
          @args = args
          @status = status
          @out = out
          @err = err
          @env = env
          @files = files

          super(<<~END)
            Commmand exited with status #{status.exitstatus}.

            COMMAND:
            #{Shellwords.join(args)}

            ENV:
            #{env.map { |k, v| "#{k}=#{v}" }.join("\n")}

            FILES:
            #{files.sort.join("\n")}

            OUT:
            #{out.strip}

            ERR:
            #{err.strip}
          END
        end
      end

      def initialize(base)
        @base = base
      end

      def open(path, mode, permissions: 0644, &block)
        path = File.join(@base, path)
        FileUtils.mkdir_p(File.dirname(path))
        File.open(path, mode, permissions, &block)
      end

      def exec!(*args, out: StringIO.new, err: StringIO.new, env: {})
        spy_out = StringIO.new
        spy_err = StringIO.new

        status = exec(*args, out: CompositeIO.new(out, spy_out), err: CompositeIO.new(err, spy_err), env: env)

        if !status.success?
          files = Find.find(@base).
            reject { |path| File.directory?(path) }.
            map { |path| path[@base.length + 1, path.length - 1] }
          raise ExecutionError.new(args: args, status: status, out: spy_out.string, err: spy_err.string, env: env, files: files)
        end
      end

      def mktmpdir(&block)
        Dir.mktmpdir(&block)
      end

      private

      def exec(*args, out: StringIO.new, err: StringIO.new, env: {})
        Open3.popen3(env, *args.flatten, chdir: @base, unsetenv_others: true) do |i, o, e, t|
          i.close
          out_reader = Thread.new { IO.copy_stream(o, out) }
          err_reader = Thread.new { IO.copy_stream(e, err) }
          out_reader.join
          err_reader.join
          t.value
        end
      end
    end
  end

  class RealFilesystemTest < Test
    def setup; @tmp = Dir.mktmpdir; end
    def teardown; FileUtils.remove_entry(@tmp); end

    def test_exec
      fs = RealFilesystem.new(@tmp)
      sandbox = fs.sandbox("sandbox")
      sandbox.open("foo.txt", "wb") do |io|
        sandbox.exec!("bash", "-c", "echo hi", out: io)
      end
      assert_equal "hi\n", File.read(File.join(@tmp, "sandbox", "foo.txt"))
    end

    def test_exec_raises
      fs = RealFilesystem.new(@tmp)
      sandbox = fs.sandbox("sandbox")
      # We don't care what happens to the file (was it partially written?)
      # because we're typically making sandboxes in tmpdirs that get thrown
      # away anyway.
      sandbox.open("foo.txt", "wb") do |io|
        error = assert_raises(Wake::RealFilesystem::Sandbox::ExecutionError) do
          sandbox.exec!("bash", "-c", "echo hi; false", out: io)
        end
        assert_equal "hi\n", error.out
        assert_equal "", error.err
      end
    end
  end

  class ProviderRegistry
    class MissingLabelError < KeyError
      def initialize(label)
        super "#{label} has not been seen"
      end
    end

    class MissingProviderError < KeyError
      def initialize(label, type)
        super "#{label} does not provide #{type}"
      end
    end

    def initialize
      @providers = {}
    end

    def [](label, types)
      @providers.fetch(label) { raise MissingLabelError.new(label) }.slice(types)
    end

    def []=(label, providers)
      @providers[label] = Holder.new(label, providers)
    end

    def of(type)
      @providers.
        select { |label, providers| providers.key?(type) }.
        map { |label, providers| [label, providers.fetch(type)] }.
        to_h
    end

    private

    class Holder
      def initialize(label, providers)
        @label = label
        @providers = providers.map { |instance| [instance.class, instance] }.to_h.freeze
      end

      def fetch(type)
        @providers.fetch(type) { raise MissingProviderError.new(@label, type) }
      end

      def key?(type)
        @providers.key?(type)
      end

      def slice(types)
        Holder.new(@label, @providers.fetch_values(*types) { |missing| raise MissingProviderError.new(@label, missing) })
      end
    end
  end

  class ProviderRegistryTest < Test
    def setup
      @registry = ProviderRegistry.new
      @label = Label["//src/main:foo"]
      @type = Class.new
      @instance = @type.new
    end

    def test_happy_path
      @registry[@label] = [@instance]
      assert_equal @instance, @registry[@label, [@type]].fetch(@type)
    end

    def test_upstream_does_not_exist
      assert_raises(ProviderRegistry::MissingLabelError) do
        @registry[@label, [@type]]
      end
    end

    def test_upstream_does_not_provide
      @registry[@label] = []
      assert_raises(ProviderRegistry::MissingProviderError) do
        @registry[@label, [@type]]
      end
    end

    def test_current_does_not_depend
      @registry[@label] = [@instance]
      providers = @registry[@label, []]
      assert_raises(ProviderRegistry::MissingProviderError) do
        providers.fetch(@type)
      end
    end
  end

  class Verifier
    def self.parse(checksum)
      Verifier.new(Digest::SHA256, checksum: checksum)
    end

    def initialize(digest, checksum: nil, observer: ->(measured_checksum) { })
      @digest = digest
      @expected_checksum = checksum
      @observer = observer
    end

    def checksum
      @expected_checksum
    end

    def observing(&observer)
      Verifier.new(@digest, checksum: @expected_checksum, observer: observer)
    end

    def wrapping(path, io, &block)
      digest = @digest.new
      block.call(Wrapper.new(io, digest))
      measured_checksum = digest.hexdigest
      if @expected_checksum
        raise "Expected #{@expected_checksum} for #{path} but got #{measured_checksum}" if @expected_checksum != measured_checksum
      else
        @observer.call(measured_checksum)
      end
    end

    private

    class Wrapper
      def initialize(io, digest)
        @io = io
        @digest = digest
      end

      def write(content)
        @digest.update(content)
        @io.write(content)
      end
    end
  end

  class Platform
    def self.from_ruby_config(config = RbConfig::CONFIG)
      new(host_os: config.fetch("host_os"))
    end

    def initialize(host_os:)
      @host_os = host_os
    end

    def host_os
      case @host_os
      when /darwin/
        :macos
      when /linux/
        :linux
      end
    end
  end

  class PlatformTest < Test
    def test_host_os_darwin_macos
      assert_equal :macos, Platform.new(host_os: "darwin19").host_os
    end

    def test_host_os_linux_linux
      assert_equal :linux, Platform.new(host_os: "i686-linux").host_os
    end
  end

  class Registry
    def initialize
      @dsl = Class.new(Dsl)
      @targets = {}
      @toolchains = []
      @toolchain_types = {}
    end

    def new_package(package)
      @dsl.new(registry: self, package: package)
    end

    def new_rule(rule_name, attributes: {}, implementation: ->(context, **attributes) { })
      schema = AttributeSchema.new(attributes)

      @dsl.class_eval(<<~END)
        def #{rule_name}(#{schema.dsl_method_parameters(:name)})
          __#{rule_name}(#{schema.dsl_method_forwarding_parameters(:name)})
        end
      END

      @dsl.define_method("__#{rule_name}") do |name:, **attributes|
        @registry.new_target(
          label: Label.new(package: @package, name: name),
          rule: implementation,
          attributes: schema.parse(attributes, package: @package),
        )
      end

      @dsl.class_eval("private :__#{rule_name}")
    end

    def new_target(label:, rule:, attributes:)
      @targets[label] = Target.new(rule: rule, attributes: attributes)
    end

    def new_toolchain_type(package:, name:, providers:)
      @toolchain_types[Label.new(package: package, name: name)] = providers
    end

    def new_toolchain(package:, name:, os:, toolchain:, toolchain_type:)
      @toolchains << Toolchain.new(
        os: os,
        toolchain: Label.parse(toolchain, package: package),
        toolchain_type: Label.parse(toolchain_type, package: package),
      )
    end

    def new_macro(macro_name, attributes: {}, implementation: ->(context, **attributes) { })
      schema = AttributeSchema.new(attributes)

      @dsl.class_eval(<<~END)
        def #{macro_name}(#{schema.dsl_method_parameters})
          __#{macro_name}(#{schema.dsl_method_forwarding_parameters})
        end
      END

      @dsl.define_method("__#{macro_name}") do |**attributes|
        @registry.expand_macro(
          package: @package,
          macro: implementation,
          attributes: schema.parse(attributes, package: @package),
        )
      end

      @dsl.class_eval("private :__#{macro_name}")
    end

    def expand_macro(package:, macro:, attributes:)
      macro.call(MacroContext.new(registry: self, package: package), **attributes)
    end

    # TODO reshape Platform to be easy to stub with something from the stdlib.
    def resolve(platform:)
      result = @targets.dup

      # TODO lazily include toolchains as we will repository targets!
      # So, don't bother with //lib/java:compiler unless one of my targets depends on it.
      @toolchains.select { |toolchain| toolchain.supports?(platform) }.each do |toolchain|
        providers = @toolchain_types.fetch(toolchain.toolchain_type)

        result[toolchain.toolchain_type] = Target.new(
          attributes: AttributeSchema.new(
            actual: Attribute.new(Label, providers: providers),
          ).parse({
            actual: toolchain.toolchain,
          }),
          rule: ->(context, actual:) {
            providers.map { |provider| actual.fetch(provider) }
          },
        )
      end

      result.freeze
    end

    private

    class Dsl
      def initialize(registry:, package:)
        @registry = registry
        @package = package
      end

      def toolchain_type(name:, providers: [])
        @registry.new_toolchain_type(package: @package, name: name, providers: providers)
      end

      def toolchain(name:, os:, toolchain:, toolchain_type:)
        @registry.new_toolchain(package: @package, name: name, os: os, toolchain: toolchain, toolchain_type: toolchain_type)
      end
    end

    class MacroContext
      def initialize(registry:, package:)
        @registry = registry
        @package = package
      end

      def package(name, &block)
        @registry.new_package([@package, name].join("/")).instance_exec(&block)
      end
    end

    class Toolchain < Struct.new(:os, :toolchain, :toolchain_type, keyword_init: true)
      def supports?(platform)
        os == platform.host_os
      end
    end
  end

  class RegistryTest < Test
    def test_platform_constraints_for_toolchains
      registry = Registry.new

      registry.new_rule(:foo_compiler)

      registry.new_macro(
        :foo_compiler_package,
        attributes: {
          name: Attribute.new(String),
        },
        implementation: ->(context, name:) {
          context.package(name) {
            foo_compiler(name: "compiler")
          }
        },
      )

      registry.new_package("foo").instance_exec do
        toolchain_type(name: "compiler")

        foo_compiler_package(name: "linux")
        foo_compiler_package(name: "macos")

        toolchain(
          name: "compiler_linux",
          os: :linux,
          toolchain: "//foo/linux:compiler",
          toolchain_type: "//foo:compiler",
        )

        toolchain(
          name: "compiler_macos",
          os: :macos,
          toolchain: "//foo/macos:compiler",
          toolchain_type: "//foo:compiler",
        )
      end

      linux_targets = registry.resolve(
        platform: Platform.new(host_os: "i686-linux"),
      )

      macos_targets = registry.resolve(
        platform: Platform.new(host_os: "darwin19"),
      )

      assert_equal Set[Label["//foo/linux:compiler"]],
        linux_targets[Label["//foo:compiler"]].dependencies

      assert_equal Set[Label["//foo/macos:compiler"]],
        macos_targets[Label["//foo:compiler"]].dependencies
    end
  end

  class Console
    def initialize(io)
      @delegate = io.tty? ? Tty.new(io) : Batch.new(io)
    end

    def report_progress(label, percentage)
      @delegate.report_progress(label, percentage)
    end

    def report_test_result(label, result)
      @delegate.report_test_result(label, result)
    end

    private

    class Batch
      def initialize(io)
        @io = io
        @progress = {}
      end

      def report_progress(label, percentage)
        return if @progress.key?(label)
        @progress[label] = true
        @io.puts(label)
      end

      def report_test_result(label, result)
        @io.puts(result)
      end
    end

    class Tty
      def initialize(io)
        @io = io
        @cols = io.winsize[1]
        @progress = {}
        @buffer = StringIO.new
      end

      def report_progress(label, percentage)
        if percentage == 100
          @progress.delete(label)
        else
          @progress[label] = percentage
        end

        format = "%s |%s%s| %2d%%"
        buffer = StringIO.new

        @progress.each do |label, percentage|
          total_cols = @cols - (format % [label, "", "", percentage]).length
          bar_cols = (percentage * total_cols / 100.0).floor
          space_cols = total_cols - bar_cols
          buffer.puts "%s |%s%s| %d%%" % [label, "=" * bar_cols, " " * space_cols, percentage]
        end

        if @buffer.length > 0
          row = @buffer.string.split("\n").size
          @io.write("\e[#{row}F") # go up to beginning of first output row
          @io.write("\e[J") # clear from cursor to end of string
        end

        @buffer.string = buffer.string
        @io.write(@buffer.string)
      end

      def report_test_result(label, result)
        @io.puts(result)
      end
    end
  end

  class ConsoleTest < Test
    def test_report_progress_batch
      io = StringIO.new
      console = Console.new(io)
      console.report_progress("foo", 15)
      console.report_progress("bar", 30)
      console.report_progress("foo", 100)
      assert_equal(<<~END, io.string)
        foo
        bar
      END
    end

    def test_report_progress_tty
      io = StringIO.new.extend(FakeTty)
      console = Console.new(io)
      console.report_progress("foo", 15)
      console.report_progress("bar", 30)
      console.report_progress("foo", 100)
      # assert_equal(<<~END, io.string)
      #   foo
      #   bar
      # END
    end

    private

    module FakeTty
      def winsize
        [24, 80]
      end

      def tty?
        true
      end
    end
  end

  # TODO connection pool?
  # TODO worker pool?
  # TODO "integration" test?
  class HttpDownloader
    def initialize(console = nil)
      @console = console
    end

    def get(url, io, original: url)
      Net::HTTP.get_response(url) do |response|
        case response
        when Net::HTTPSuccess
          response.read_body(CompositeIO.new(io, Progress.new(@console, original, response["content-length"].to_i)))
        when Net::HTTPRedirection
          get(URI.parse(response["location"]), io, original: original)
        else
          response.error!
        end
      end
    end

    private

    class Progress
      def initialize(console, url, total)
        @console = console
        @label = url.path.split("/").last
        @total = total
        @current = 0
      end

      def write(chunk)
        @current += chunk.size
        @console.report_progress(@label, (@current * 100.0 / @total).floor)
        chunk.size
      end
    end
  end

  class CompositeIO
    def initialize(*ios)
      @ios = ios
    end

    def write(*args)
      # TODO this gets hinky when the answers are different!
      @ios.map { |io| io.write(*args) }.max
    end

    def <<(*args)
      write(*args)
    end
  end

  # Struct saves the boilerplate of making Label work as a Hash key.
  class Label < Struct.new(:package, :name, keyword_init: true)
    def self.[](string)
      parse(string)
    end

    def self.parse(string, package: nil)
      head, rest = string.split(":", 2)

      if head.start_with? "//"
        parsed_package = head[2..-1]
        parsed_name = rest
      elsif rest
        parsed_package = package
        parsed_name = rest
      else
        parsed_package = package
        parsed_name = head
      end

      if parsed_package.nil? || parsed_name.nil?
        raise "Invalid label: #{string.inspect}"
      end

      Label.new(package: parsed_package, name: parsed_name).freeze
    end

    def inspect
      "#<label #{to_s}>"
    end

    def to_s
      "//#{package}:#{name}"
    end
  end

  class LabelTest < Test
    def test_parse
      label = Label.parse("//src/main:foo")
      assert_equal "src/main", label.package
      assert_equal "foo", label.name
    end

    def test_parse_without_name
      assert_raises { Label.parse("//src/main") }
    end

    def test_parse_relative
      label = Label.parse(":foo", package: "src/main")
      assert_equal "src/main", label.package
      assert_equal "foo", label.name
    end

    def test_parse_relative_without_package
      assert_raises { Label.parse(":foo") }
    end

    def test_parse_filename
      label = Label.parse("foo.kt", package: "src/main")
      assert_equal "src/main", label.package
      assert_equal "foo.kt", label.name
    end
  end

  class Target
    def initialize(rule:, attributes:)
      @rule = rule
      @attributes = attributes
    end

    def dependencies
      @attributes.dependencies
    end

    def invoke(context)
      context.invoke(@rule, @attributes)
    end
  end

  class TargetTest < Test
    def test_dependencies
      target = Target.new(
        rule: ->(context, **attributes) { },
        attributes: AttributeSchema.new(
          thing: Attribute.new(Label),
          things: Attribute.new(Label, list: true),
          irrelevant_things: Attribute.new(String, list: true),
        ).parse({
          thing: "//src/main:quux",
          things: [
            "//src/main:bar",
            "//src/main:baz",
          ],
          irrelevant_things: [
            "a.rb",
            "b.rb",
          ],
        }),
      )
      assert_equal [
        Label["//src/main:bar"],
        Label["//src/main:baz"],
        Label["//src/main:quux"],
      ].to_set, target.dependencies
    end
  end

  class AttributeSchema
    def initialize(fields = {})
      @fields = fields
    end

    def dependencies(values)
      @fields.map { |name, type| type.dependencies(values.fetch(name)) }.reduce(Set.new, &:merge).freeze
    end

    def dsl_method_parameters(prefix = nil)
      extra = prefix ? ["#{prefix}:"] : []
      extra.concat(@fields.map { |name, type| type.as_method_parameter(name) }).join(", ")
    end

    def dsl_method_forwarding_parameters(prefix = nil)
      extra = prefix ? ["#{prefix}: #{prefix}"] : []
      extra.concat(@fields.keys.map { |name| "#{name}: #{name}" }).join(", ")
    end

    def parse(raw, **options)
      Attributes.new(self, values(raw, **options))
    end

    def using(providers, values)
      @fields.map { |name, type| [name, type.using(providers, values.fetch(name))] }.to_h.freeze
    end

    private

    def values(raw, **options)
      @fields.map { |name, type| [name, type.parse(raw[name], **options)] }.to_h.freeze
    end
  end

  class AttributeSchemaTest < Test
    def test_dsl_method_parameters
      schema = AttributeSchema.new(
        deps: Attribute.new(Label, list: true),
        compiler: Attribute.new(Label, default: "//lib:compiler"),
        strip_components: Attribute.new(PathCleaner, default: 0),
        build: Attribute.new(Proc, default: ->() { }),
        neverlink: Attribute.new(TrueClass, default: false),
      )
      assert_equal "name:, deps:, compiler: \"//lib:compiler\", strip_components: 0, build: ->() { }, neverlink: false", schema.dsl_method_parameters(:name)
    end

    def test_dsl_method_forwarding_parameters
      schema = AttributeSchema.new(
        deps: Attribute.new(Label),
        compiler: Attribute.new(Label),
      )
      assert_equal "name: name, deps: deps, compiler: compiler", schema.dsl_method_forwarding_parameters(:name)
    end
  end

  class Attributes
    def initialize(schema, values)
      @schema = schema
      @values = values
    end

    def dependencies
      @schema.dependencies(@values)
    end

    def using(providers)
      @schema.using(providers, @values)
    end

    def to_hash
      @values
    end
  end

  class Attribute
    def initialize(type, list: false, default: nil, providers: [])
      @type = type
      @list = list
      @default = default
      @providers = providers
    end

    def as_method_parameter(name)
      !@default.nil? ? "#{name}: #{@type == Proc ? "->() { }" : @default.inspect}" : "#{name}:"
    end

    def dependencies(value)
      @type == Label ? (@list ? Set.new(value) : Set.new([value])) : Set.new
    end

    def parse(raw_value, **options)
      if @list
        Array(raw_value || @default).map { |item| try_parse(item, **options) }.freeze
      else
        try_parse(raw_value || @default, **options).freeze
      end
    end

    def using(providers, value)
      if @type == Label && !@list
        providers[value, @providers]
      elsif @type == Label && @list
        value.map { |v| providers[v, @providers] }
      else
        value
      end
    end

    private

    def try_parse(raw_value, **options)
      if @type === raw_value
        raw_value
      elsif @type == Label
        @type.parse(raw_value, **options)
      elsif @type == TrueClass && raw_value == false
        raw_value
      else
        @type.parse(raw_value)
      end
    end
  end

  class AttributeTest < Test
    def test_parse
      assert_equal URI.parse("https://example.com"), Attribute.new(URI).parse("https://example.com")
      assert Attribute.new(TrueClass).parse(true)
    end

    def test_parse_already_parsed
      assert_equal URI.parse("https://example.com"), Attribute.new(URI).parse(URI.parse("https://example.com"))
    end

    def test_parse_default
      assert_equal URI.parse("https://example.com"), Attribute.new(URI, default: "https://example.com").parse(nil)
      assert Attribute.new(TrueClass, default: true).parse(nil)
      assert !Attribute.new(TrueClass, default: false).parse(nil)
    end

    def test_parse_nil_no_default
      # TODO make the error messages better. Requires attribute to know or be passed its name, which we're not doing yet.
      assert_raises { Attribute.new(Label).parse(nil) }
      assert_raises { Attribute.new(MavenCoordinates).parse(nil) }
      assert_raises { Attribute.new(String).parse(nil) }
      assert_raises { Attribute.new(TrueClass).parse(nil) }
      assert_raises { Attribute.new(URI).parse(nil) }
    end

    def test_parse_list
      assert_equal [URI.parse("https://example.com")], Attribute.new(URI, list: true).parse(["https://example.com"])
    end

    def test_parse_list_single
      assert_equal [URI.parse("https://example.com")], Attribute.new(URI, list: true).parse("https://example.com")
    end

    def test_parse_list_empty
      assert_equal [], Attribute.new(URI, list: true).parse(nil)
    end

    def test_parse_relative_label
      assert_equal Label["//src/main:foo"], Attribute.new(Label).parse(":foo", package: "src/main")
    end
  end

  class Extractor
    def self.parse(key)
      Extractor.new(key)
    end

    def initialize(format)
      @format = format
    end

    def extract(io, strip_components:, &collector)
      extractor(strip_components).call(nil, io) do |entry_path, entry_io|
        collector.call(entry_path, entry_io)
      end
    end

    def to_s
      "Extractor(#{@format})"
    end

    private

    def extractor(strip_components)
      case @format
      when :tar_gz
        Gzip.new(Tar.new(strip_components))
      when :zip
        Zip.new(strip_components)
      else
        raise "Unsupported Extractor #{@format}"
      end
    end
  end

  class Gzip
    def initialize(delegate)
      @delegate = delegate
    end

    def call(name, io, &collector)
      Zlib::GzipReader.wrap(io) do |gz|
        @delegate.call(name, gz, &collector)
      end
    end
  end

  class GzipTest < Test
    def test_extracts_content
      contents = ""

      StringIO.open(contents) do |io|
        Zlib::GzipWriter.wrap(io) do |gz|
          gz.write("Hello!")
        end
      end

      entries = {}
      gzip = Gzip.new(PathCleaner.new(strip_components: 0))
      gzip.call("file.txt", StringIO.new(contents)) { |path, io|
        entries[path] = io.read
      }

      assert_equal ["file.txt"], entries.keys
      assert_equal "Hello!", entries["file.txt"]
    end
  end

  class Tar
    def initialize(delegate)
      @delegate = delegate
    end

    def call(_, io, &collector)
      Gem::Package::TarReader.new(io) do |tar|
        tar.each do |entry|
          @delegate.call(entry.full_name, entry, &collector) if entry.file?
        end
      end
    end
  end

  class TarTest < Test
    def test_extracts_files
      contents = ""

      StringIO.open(contents) do |io|
        Gem::Package::TarWriter.new(io) do |tar|
          tar.add_file_simple("file.txt", 0644, 6) do |file|
            file.write("Hello!")
          end
        end
      end

      entries = {}
      tar = Tar.new(PathCleaner.new(strip_components: 0))
      tar.call(nil, StringIO.new(contents)) { |path, io| entries[path] = io.read }
      assert_equal ["file.txt"], entries.keys
      assert_equal "Hello!", entries["file.txt"]
    end

    def test_skips_directories
      contents = ""

      StringIO.open(contents) do |io|
        Gem::Package::TarWriter.new(io) do |tar|
          tar.mkdir("other", 0755)
        end
      end

      entries = {}
      tar = Tar.new(PathCleaner.new(strip_components: 0))
      tar.call(nil, StringIO.new(contents)) { |path, io| entries[path] = io.read }
      assert_equal [], entries.keys
    end
  end

  class Zip
    def initialize(delegate)
      @delegate = delegate
    end

    def call(name, io, &collector)
      Reader.new(io).each do |name, io|
        @delegate.call(name, io, &collector)
      end
    end

    # https://en.wikipedia.org/wiki/Zip_(file_format)
    class Reader
      MAX_END_OF_CDS_SIZE = 65_536 + 18
      END_OF_CDS = [0x06054b50].pack("V")
      CDIR_ENTRY_STATIC_HEADER_LENGTH = 46
      LOCAL_ENTRY_STATIC_HEADER_LENGTH = 30

      def initialize(io)
        @io = io
      end

      def each(&block)
        begin
          @io.seek(-MAX_END_OF_CDS_SIZE, IO::SEEK_END)
        rescue Errno::EINVAL
          @io.seek(0, IO::SEEK_SET)
        end

        buffer = @io.read
        record = EndOfCentralDirectoryRecord.parse(buffer[buffer.rindex(END_OF_CDS)..-1])

        @io.seek(record.offset, IO::SEEK_SET)

        headers = record.size.times.map do
          header = CentralDirectoryFileHeader.parse(@io.read(CDIR_ENTRY_STATIC_HEADER_LENGTH))
          header.file_name = @io.read(header.file_name_length)
          header.extra_field = @io.read(header.extra_field_length)
          header.file_comment = @io.read(header.file_comment_length)
          header.freeze
        end

        headers.select(&:file?).each do |header|
          @io.seek(header.offset)

          local = LocalFileHeader.parse(@io.read(LOCAL_ENTRY_STATIC_HEADER_LENGTH))
          local.file_name = @io.read(local.file_name_length)
          local.extra_field = @io.read(local.extra_field_length)
          local.freeze

          block.call local.file_name, local.decompress(@io)
        end
      end

      class EndOfCentralDirectoryRecord < Struct.new(
        :end_of_central_directory_signature,
        :number_of_this_disk,
        :disk_where_central_directory_starts,
        :number_of_central_directory_records_on_this_disk,
        :total_number_of_central_directory_records,
        :size_of_central_directory_in_bytes,
        :offset_to_start_of_central_directory_relative_to_start_of_archive,
        :comment_length,
        :comment
      )
        alias_method :offset, :offset_to_start_of_central_directory_relative_to_start_of_archive
        alias_method :size, :number_of_central_directory_records_on_this_disk

        def self.parse(buffer)
          new(*buffer.unpack("VvvvvVVva*")).freeze
        end
      end

      class CentralDirectoryFileHeader < Struct.new(
        :central_directory_file_header_signature,
        :version_made_by,
        :filesystem_type,
        :version_needed_to_extract,
        :general_purpose_bit_flag,
        :compression_method,
        :file_last_modification_time,
        :file_last_modification_date,
        :crc_32_of_uncompressed_data,
        :compressed_size,
        :uncompressed_size,
        :file_name_length,
        :extra_field_length,
        :file_comment_length,
        :disk_number_where_file_starts,
        :internal_file_attributes,
        :external_file_attributes,
        :relative_offset_of_local_file_header,
        :file_name,
        :extra_field,
        :file_comment,
      )
        alias_method :offset, :relative_offset_of_local_file_header

        def self.parse(buffer)
          new(*buffer.unpack("VCCvvvvvVVVvvvvvVV"))
        end

        def file?
          if filesystem_type != 3 # Unix
            raise "Unknown filesystem_type #{filesystem_type.inspect} for entry #{file_name.inspect}"
          end

          # 4 means directory, 10 means symlink
          external_file_attributes >> 28 == 8
        end
      end

      class LocalFileHeader < Struct.new(
        :local_file_header_signature,
        :version_needed_to_extract,
        :general_purpose_bit_flag,
        :compression_method,
        :file_last_modification_time,
        :file_last_modification_date,
        :crc_32_of_uncompressed_data,
        :compressed_size,
        :uncompressed_size,
        :file_name_length,
        :extra_field_length,
        :file_name,
        :extra_field,
      )
        def self.parse(buffer)
          new(*buffer.unpack("VvvvvvVVVvv"))
        end

        def decompress(io)
          case compression_method
          when 0
            IOSlice.new(io, io.pos, compressed_size)
          when 8
            Inflater.new(IOSlice.new(io, io.pos, compressed_size))
          else
            raise "Unsupported compression_method #{compression_method.inspect} for entry #{file_name.inspect}"
          end
        end
      end
    end
  end

  class ZipTest < Test
    require "base64"

    def test_extracts_files
      # This is a zip file containing one file, path/to/file.txt, with the contents "Hello!\n".
      encoded = <<~END.gsub("\n", "")
        UEsDBAoAAAAAAAZ2xVAAAAAAAAAAAAAAAAAFABwAcGF0aC9VVAkAA2uT2l54
        k9pedXgLAAEE9QEAAAQUAAAAUEsDBAoAAAAAAAl2xVAAAAAAAAAAAAAAAAAI
        ABwAcGF0aC90by9VVAkAA3GT2l56k9pedXgLAAEE9QEAAAQUAAAAUEsDBAoA
        AAAAAE92xVCe2EKwBwAAAAcAAAAQABwAcGF0aC90by9maWxlLnR4dFVUCQAD
        9ZPaXveT2l51eAsAAQT1AQAABBQAAABIZWxsbyEKUEsBAh4DCgAAAAAABnbF
        UAAAAAAAAAAAAAAAAAUAGAAAAAAAAAAQAO1BAAAAAHBhdGgvVVQFAANrk9pe
        dXgLAAEE9QEAAAQUAAAAUEsBAh4DCgAAAAAACXbFUAAAAAAAAAAAAAAAAAgA
        GAAAAAAAAAAQAO1BPwAAAHBhdGgvdG8vVVQFAANxk9pedXgLAAEE9QEAAAQU
        AAAAUEsBAh4DCgAAAAAAT3bFUJ7YQrAHAAAABwAAABAAGAAAAAAAAQAAAKSB
        gQAAAHBhdGgvdG8vZmlsZS50eHRVVAUAA/WT2l51eAsAAQT1AQAABBQAAABQ
        SwUGAAAAAAMAAwDvAAAA0gAAAAAA
      END

      decoded = Base64.decode64(encoded)

      entries = {}
      zip = Zip.new(PathCleaner.new(strip_components: 0))
      zip.call(nil, StringIO.new(decoded)) { |path, io| entries[path] = io.read }
      assert_equal ["path/to/file.txt"], entries.keys
      assert_equal "Hello!\n", entries["path/to/file.txt"]
    end
  end

  class Inflater
    def initialize(src)
      @src = src
      @inflate = Zlib::Inflate.new(-Zlib::MAX_WBITS)
      @buffer = ""
    end

    # TODO this implementation is a bit convoluted, lifted verbatim from rubyzip.
    def read(length = nil, outbuf = "")
      return (length.nil? || length.zero? ? "" : nil) if eof?

      while length.nil? || (@buffer.bytesize < length)
        break if input_finished?
        @buffer << produce_input
      end

      outbuf.replace(@buffer.slice!(0...(length || @buffer.bytesize)))
    end

    private

    def eof?
      @buffer.empty? && input_finished?
    end

    def produce_input
      retried = 0
      begin
        @inflate.inflate(@src.read(32_768))
      rescue Zlib::BufError
        raise if retried >= 5
        retried += 1
        retry
      end
    end

    def input_finished?
      @inflate.finished?
    end
  end

  class InflaterTest < Test
    def setup
      deflate = Zlib::Deflate.new(Zlib::DEFAULT_COMPRESSION, -Zlib::MAX_WBITS)
      @io = Inflater.new(StringIO.new(deflate.deflate("Hello, world!", Zlib::FINISH)))
    end

    def test_read
      assert_equal "Hello, world!", @io.read
    end

    def test_read_length
      assert_equal "Hello", @io.read(5)
      assert_equal ", wor", @io.read(5)
      assert_equal "ld!", @io.read(5)
    end

    def test_eof_read_nil
      @io.read
      assert_equal "", @io.read
    end

    def test_eof_read_zero
      @io.read
      assert_equal "", @io.read(0)
    end

    def test_eof_read_length
      @io.read
      assert_nil @io.read(2)
    end

    def test_io_copy_stream
      dest = StringIO.new
      IO.copy_stream(@io, dest)
      assert_equal "Hello, world!", dest.string
    end
  end

  class IOSlice
    def initialize(source, start, length)
      @source = source
      @source.seek(start)
      @length = length
    end

    def read(length = nil, outbuf = "")
      buffer = nil

      if length == 0
        buffer = ""
      elsif length.nil?
        buffer = @source.read(@length)
        @length = 0
      elsif (length = [@length, length].min) > 0
        buffer = @source.read(length)
        @length -= length
      end

      if buffer
        outbuf.replace(buffer)
      end
    end
  end

  class IOSliceTest < Test
    def setup
      @io = IOSlice.new(StringIO.new("Hello, world!"), 7, 5)
    end

    def test_read
      assert_equal "world", @io.read
    end

    def test_read_length
      assert_equal "wo", @io.read(2)
      assert_equal "rl", @io.read(2)
      assert_equal "d", @io.read(2)
    end

    def test_eof_read_nil
      @io.read
      assert_equal "", @io.read
    end

    def test_eof_read_zero
      @io.read
      assert_equal "", @io.read(0)
    end

    def test_eof_read_length
      @io.read
      assert_nil @io.read(2)
    end

    def test_learning_stringio_eof_read_length_outbuf
      outbuf = "foo"
      io = StringIO.new("")
      io.read(2, outbuf)
      assert_equal "", outbuf
    end

    def test_io_copy_stream
      dest = StringIO.new
      IO.copy_stream(@io, dest)
      assert_equal "world", dest.string
    end
  end

  class PathCleaner
    def self.parse(strip_components)
      new(strip_components: strip_components)
    end

    def initialize(strip_components:)
      @strip_components = strip_components
    end

    def call(name, io, &collector)
      path = Pathname.new(name).cleanpath.to_path
      components = path.split("/")
      components.shift(@strip_components)
      result = components.join("/")
      return if result.empty?
      collector.call(result, io)
    end

    def to_s
      "PathCleaner(strip_components: #{@strip_components})"
    end
  end

  class PathCleanerTest < Test
    def test_cleans_paths
      result = nil
      PathCleaner.new(strip_components: 0).
        call("./path/to/file.txt", nil) { |name| result = name }
      assert_equal "path/to/file.txt", result
    end

    def test_strips_components
      result = nil
      PathCleaner.new(strip_components: 2).
        call("./path/to/my/file.txt", nil) { |name| result = name }
      assert_equal "my/file.txt", result
    end

    def test_skips_stripped_components
      result = nil
      PathCleaner.new(strip_components: 2).
        call("./bar.txt", nil) { |name| result = name }
      assert_nil result
    end
  end

  class MavenCoordinates
    def self.parse(string)
      string.match %r{^([^:]+):([^:]+):([^:]+)$} do |match|
        new(match[1], match[2], match[3])
      end
    end

    def initialize(group, artifact, version, classifier: nil, packaging: :jar)
      @group = group
      @artifact = artifact
      @version = version
      @classifier = classifier
      @packaging = packaging
    end

    def filename(suffix: nil)
      [[@artifact, @version, @classifier].compact.join("-"), @packaging, suffix].compact.join(".")
    end

    def package_path
      "#{@group.gsub(".", "_")}/#{@artifact.gsub("-", "_")}"
    end

    def sources
      self.class.new(@group, @artifact, @version, classifier: :sources, packaging: @packaging)
    end

    def url(repository, suffix: nil)
      repository + [repository.path, *@group.split("."), @artifact, @version, filename(suffix: suffix)].join("/")
    end
  end

  class MavenCoordinatesTest < Test
    def setup
      @subject = MavenCoordinates.parse("a.b.c:x-y-z:1.2.3")
    end

    def test_filename
      assert_equal "x-y-z-1.2.3.jar", @subject.filename
    end

    def test_filename_with_suffix
      assert_equal "x-y-z-1.2.3.jar.md5", @subject.filename(suffix: :md5)
    end

    def test_package_path
      assert_equal "a_b_c/x_y_z", @subject.package_path
    end

    def test_sources_filename
      assert_equal "x-y-z-1.2.3-sources.jar", @subject.sources.filename
    end

    def test_url
      assert_equal URI.parse("https://example.com/maven/a/b/c/x-y-z/1.2.3/x-y-z-1.2.3.jar"),
        @subject.url(URI.parse("https://example.com/maven"))
    end
  end

  class Plan
    def initialize(roots, &children)
      @blocked = {}
      @blocking = {}
      @available = Queue.new
      @mutex = Mutex.new

      traverse = lambda do |node, parent = nil|
        if !@blocked.key?(node)
          @blocked[node] = 0
          @blocking[node] = []
          children[node].each { |child| traverse[child, node] }
        end

        if parent
          @blocked[parent] += 1
          @blocking[node] << parent
        end
      end

      roots.each(&traverse)

      @blocked.each { |node, count| @available << node if count.zero? }
      @blocked.delete_if { |node, count| count.zero? }
    end

    def each(&block)
      if !@available.empty?
        while node = @available.pop
          block.call(node)
          cleanup(node)
        end
      end
    end

    private

    def cleanup(node)
      @mutex.synchronize do
        @blocking[node].each do |parent|
          @blocked[parent] -= 1
          if @blocked[parent] == 0
            @blocked.delete(parent)
            @available << parent
          end
        end

        if @blocked.empty?
          @available.close
        end
      end
    end
  end

  class PlanTest < Test
    def test_each
      #   a     b
      #  / \    |
      # c   d   e
      #    / \ / \
      #   f   g   h
      #      / \
      #     i   j
      edges = {
        a: [:c, :d],
        b: [:e],
        c: [],
        d: [:f, :g],
        e: [:g, :h],
        f: [],
        g: [:i, :j],
        h: [],
        i: [],
        j: [],
      }
      record = []
      plan = Plan.new([:a, :b]) { |node| edges[node] }
      plan.each { |node| record << node }
      assert_equal [:c, :f, :i, :j, :h, :g, :d, :e, :a, :b], record
    end

    def test_each_nothing
      record = []
      plan = Plan.new([]) { |node| [] }
      plan.each { |node| record << node }
      assert_equal [], record
    end

    def test_each_no_dependencies
      record = []
      plan = Plan.new([:a, :b]) { |node| [] }
      plan.each { |node| record << node }
      assert_equal [:a, :b], record
    end
  end

  class LintTest < Test
    def test_all_tests_are_tests
      assert_equal [], Wake.constants.
                     select { |name| name =~ /^.+Test$/ }.
                     map { |name| Wake.const_get(name) }.
                     select { |klass| !klass.ancestors.include?(Test) }
    end
  end

  if __FILE__ == $0 && !Kernel.const_defined?(:Minitest)
    exit Wake.run
  end
end
